{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chapter 11 â€“ Deep Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_This notebook contains all the sample code and solutions to the exercises in chapter 11._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's make sure this notebook works well in both python 2 and 3, import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "#def reset_graph(seed=42):\n",
    "#    tf.reset_default_graph()\n",
    "#    tf.set_random_seed(seed)\n",
    "#    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"deep\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanishing/Exploding Gradients Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure sigmoid_saturation_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.linspace(-5, 5, 200)\n",
    "\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [1, 1], 'k--')\n",
    "plt.plot([0, 0], [-0.2, 1.2], 'k-')\n",
    "plt.plot([-5, 5], [-3/4, 7/4], 'g--')\n",
    "plt.plot(z, logit(z), \"b-\", linewidth=2)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Saturating', xytext=(3.5, 0.7), xy=(5, 1), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('Saturating', xytext=(-3.5, 0.3), xy=(-5, 0), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('Linear', xytext=(2, 0.2), xy=(0, 0.5), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.grid(True)\n",
    "plt.title(\"Sigmoid activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.2, 1.2])\n",
    "\n",
    "save_fig(\"sigmoid_saturation_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xavier and He Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the book uses `tensorflow.contrib.layers.fully_connected()` rather than `tf.layers.dense()` (which did not exist when this chapter was written). It is now preferable to use `tf.layers.dense()`, because anything in the contrib module may change or be deleted without notice. The `dense()` function is almost identical to the `fully_connected()` function. The main differences relevant to this chapter are:\n",
    "* several parameters are renamed: `scope` becomes `name`, `activation_fn` becomes `activation` (and similarly the `_fn` suffix is removed from other parameters such as `normalizer_fn`), `weights_initializer` becomes `kernel_initializer`, etc.\n",
    "* the default `activation` is now `None` rather than `tf.nn.relu`.\n",
    "* it does not support `tensorflow.contrib.framework.arg_scope()` (introduced later in chapter 11).\n",
    "* it does not support regularizer params (introduced later in chapter 11)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import TensorBoard, LearningRateScheduler\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_init = tf.keras.initializers.he_normal(seed=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonsaturating Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leaky ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(z, alpha=0.01):\n",
    "    return np.maximum(alpha*z, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure leaky_relu_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, leaky_relu(z, 0.05), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([0, 0], [-0.5, 4.2], 'k-')\n",
    "plt.grid(True)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Leak', xytext=(-3.5, 0.5), xy=(-5, -0.2), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.title(\"Leaky ReLU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.5, 4.2])\n",
    "\n",
    "save_fig(\"leaky_relu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing Leaky ReLU in TensorFlow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "def leaky_relu(z, name=None):\n",
    "    return tf.maximum(alpha * z, z, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a neural network on MNIST using the Leaky ReLU. First let's create the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_2d, y_train_0), (X_test_2d, y_test_0) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train_2d.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test_2d.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "y_train = y_train_0.astype(np.int32)\n",
    "y_test = y_test_0.astype(np.int32)\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with Leaky ReLU and He Initialization\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(n_hidden1, kernel_initializer=he_init, activation=leaky_relu),\n",
    "#    keras.layers.Dense(n_hidden1, kernel_initializer=he_init, activation=tf.nn.leaky_relu),\n",
    "    keras.layers.Dense(n_hidden2, kernel_initializer=he_init, activation=leaky_relu),\n",
    "#    keras.layers.Dense(n_outputs, kernel_initializer=he_init, activation=None')\n",
    "    keras.layers.Dense(n_outputs, kernel_initializer=he_init, activation='softmax')\n",
    "])    \n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelelu = keras.Sequential([\n",
    "    keras.layers.Dense(n_hidden1, kernel_initializer=he_init, activation='elu'),\n",
    "#    keras.layers.Dense(n_hidden1, kernel_initializer=he_init, activation=tf.nn.leaky_relu),\n",
    "    keras.layers.Dense(n_hidden2, kernel_initializer=he_init, activation='elu'),\n",
    "#    keras.layers.Dense(n_outputs, kernel_initializer=he_init, activation=None')\n",
    "    keras.layers.Dense(n_outputs, kernel_initializer=he_init, activation='softmax')\n",
    "])    \n",
    "\n",
    "modelelu.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with ReLU and He initialization\n",
    "model2 = keras.Sequential([\n",
    "    keras.layers.Dense(n_hidden1, kernel_initializer=he_init, activation='relu'),\n",
    "#    keras.layers.Dense(n_hidden1, kernel_initializer=he_init, activation=tf.nn.leaky_relu),\n",
    "    keras.layers.Dense(n_hidden2, kernel_initializer=he_init, activation='relu'),\n",
    "#    keras.layers.Dense(n_outputs, kernel_initializer=he_init, activation=None')\n",
    "    keras.layers.Dense(n_outputs, kernel_initializer=he_init, activation='softmax')\n",
    "])    \n",
    "\n",
    "model2.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with Leaky ReLU without He initialization\n",
    "model3 = keras.Sequential([\n",
    "    keras.layers.Dense(n_hidden1, activation=leaky_relu),\n",
    "#    keras.layers.Dense(n_hidden1, kernel_initializer=he_init, activation=tf.nn.leaky_relu),\n",
    "    keras.layers.Dense(n_hidden2, activation=leaky_relu),\n",
    "#    keras.layers.Dense(n_outputs, kernel_initializer=he_init, activation=None')\n",
    "    keras.layers.Dense(n_outputs, activation='softmax')\n",
    "])    \n",
    "\n",
    "model3.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with ReLU without He initialization\n",
    "model4 = keras.Sequential([\n",
    "    keras.layers.Dense(n_hidden1, activation='relu'),\n",
    "#    keras.layers.Dense(n_hidden1, kernel_initializer=he_init, activation=tf.nn.leaky_relu),\n",
    "    keras.layers.Dense(n_hidden2, activation='relu'),\n",
    "#    keras.layers.Dense(n_outputs, kernel_initializer=he_init, activation=None')\n",
    "    keras.layers.Dense(n_outputs, activation='softmax')\n",
    "])    \n",
    "\n",
    "model4.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log_dir=\"logs_11/model/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir=\"logs_11/model/\"\n",
    "file_writer = tf.summary.create_file_writer(log_dir + \"/metrics\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, \n",
    "                                                      update_freq=10, profile_batch = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "55000/55000 [==============================] - 2s 30us/sample - loss: 0.9068 - accuracy: 0.7708 - val_loss: 0.4570 - val_accuracy: 0.8860\n",
      "Epoch 2/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.4078 - accuracy: 0.8884 - val_loss: 0.3410 - val_accuracy: 0.9072\n",
      "Epoch 3/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.3358 - accuracy: 0.9059 - val_loss: 0.2985 - val_accuracy: 0.9190\n",
      "Epoch 4/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.2992 - accuracy: 0.9157 - val_loss: 0.2705 - val_accuracy: 0.9280\n",
      "Epoch 5/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.2740 - accuracy: 0.9233 - val_loss: 0.2509 - val_accuracy: 0.9324\n",
      "Epoch 6/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.2543 - accuracy: 0.9279 - val_loss: 0.2340 - val_accuracy: 0.9354\n",
      "Epoch 7/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.2382 - accuracy: 0.9333 - val_loss: 0.2220 - val_accuracy: 0.9402\n",
      "Epoch 8/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.2244 - accuracy: 0.9365 - val_loss: 0.2101 - val_accuracy: 0.9424\n",
      "Epoch 9/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.2122 - accuracy: 0.9402 - val_loss: 0.2002 - val_accuracy: 0.9462\n",
      "Epoch 10/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.2014 - accuracy: 0.9437 - val_loss: 0.1904 - val_accuracy: 0.9488\n",
      "Epoch 11/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1915 - accuracy: 0.9464 - val_loss: 0.1830 - val_accuracy: 0.9518\n",
      "Epoch 12/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1828 - accuracy: 0.9488 - val_loss: 0.1755 - val_accuracy: 0.9526\n",
      "Epoch 13/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.1746 - accuracy: 0.9510 - val_loss: 0.1689 - val_accuracy: 0.9544\n",
      "Epoch 14/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.1673 - accuracy: 0.9534 - val_loss: 0.1624 - val_accuracy: 0.9574\n",
      "Epoch 15/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.1604 - accuracy: 0.9547 - val_loss: 0.1575 - val_accuracy: 0.9586\n",
      "Epoch 16/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1542 - accuracy: 0.9565 - val_loss: 0.1526 - val_accuracy: 0.9604\n",
      "Epoch 17/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1480 - accuracy: 0.9582 - val_loss: 0.1483 - val_accuracy: 0.9610\n",
      "Epoch 18/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1426 - accuracy: 0.9601 - val_loss: 0.1443 - val_accuracy: 0.9624\n",
      "Epoch 19/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1376 - accuracy: 0.9609 - val_loss: 0.1399 - val_accuracy: 0.9636\n",
      "Epoch 20/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1327 - accuracy: 0.9631 - val_loss: 0.1363 - val_accuracy: 0.9632\n",
      "Epoch 21/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1282 - accuracy: 0.9640 - val_loss: 0.1330 - val_accuracy: 0.9652\n",
      "Epoch 22/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1241 - accuracy: 0.9654 - val_loss: 0.1297 - val_accuracy: 0.9666\n",
      "Epoch 23/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1200 - accuracy: 0.9665 - val_loss: 0.1270 - val_accuracy: 0.9668\n",
      "Epoch 24/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.1160 - accuracy: 0.9680 - val_loss: 0.1239 - val_accuracy: 0.9668\n",
      "Epoch 25/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.1125 - accuracy: 0.9687 - val_loss: 0.1211 - val_accuracy: 0.9664\n",
      "Epoch 26/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1093 - accuracy: 0.9700 - val_loss: 0.1195 - val_accuracy: 0.9682\n",
      "Epoch 27/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1058 - accuracy: 0.9710 - val_loss: 0.1179 - val_accuracy: 0.9692\n",
      "Epoch 28/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1028 - accuracy: 0.9717 - val_loss: 0.1143 - val_accuracy: 0.9702\n",
      "Epoch 29/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0999 - accuracy: 0.9719 - val_loss: 0.1126 - val_accuracy: 0.9698\n",
      "Epoch 30/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0972 - accuracy: 0.9733 - val_loss: 0.1104 - val_accuracy: 0.9708\n",
      "Epoch 31/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0944 - accuracy: 0.9743 - val_loss: 0.1084 - val_accuracy: 0.9712\n",
      "Epoch 32/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0918 - accuracy: 0.9748 - val_loss: 0.1060 - val_accuracy: 0.9722\n",
      "Epoch 33/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0893 - accuracy: 0.9753 - val_loss: 0.1060 - val_accuracy: 0.9724\n",
      "Epoch 34/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0871 - accuracy: 0.9758 - val_loss: 0.1034 - val_accuracy: 0.9720\n",
      "Epoch 35/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0848 - accuracy: 0.9767 - val_loss: 0.1014 - val_accuracy: 0.9722\n",
      "Epoch 36/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0826 - accuracy: 0.9774 - val_loss: 0.1003 - val_accuracy: 0.9728\n",
      "Epoch 37/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0804 - accuracy: 0.9778 - val_loss: 0.0994 - val_accuracy: 0.9734\n",
      "Epoch 38/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0784 - accuracy: 0.9785 - val_loss: 0.0996 - val_accuracy: 0.9728\n",
      "Epoch 39/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0768 - accuracy: 0.9789 - val_loss: 0.0971 - val_accuracy: 0.9746\n",
      "Epoch 40/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0746 - accuracy: 0.9798 - val_loss: 0.0955 - val_accuracy: 0.9748\n",
      "Epoch 41/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0729 - accuracy: 0.9801 - val_loss: 0.0944 - val_accuracy: 0.9754\n",
      "Epoch 42/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0712 - accuracy: 0.9806 - val_loss: 0.0936 - val_accuracy: 0.9752\n",
      "Epoch 43/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0694 - accuracy: 0.9811 - val_loss: 0.0918 - val_accuracy: 0.9754\n",
      "Epoch 44/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0677 - accuracy: 0.9819 - val_loss: 0.0926 - val_accuracy: 0.9748\n",
      "Epoch 45/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0664 - accuracy: 0.9818 - val_loss: 0.0913 - val_accuracy: 0.9756\n",
      "Epoch 46/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0648 - accuracy: 0.9823 - val_loss: 0.0894 - val_accuracy: 0.9762\n",
      "Epoch 47/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0634 - accuracy: 0.9828 - val_loss: 0.0885 - val_accuracy: 0.9754\n",
      "Epoch 48/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0619 - accuracy: 0.9837 - val_loss: 0.0884 - val_accuracy: 0.9746\n",
      "Epoch 49/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0604 - accuracy: 0.9838 - val_loss: 0.0875 - val_accuracy: 0.9760\n",
      "Epoch 50/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0591 - accuracy: 0.9844 - val_loss: 0.0874 - val_accuracy: 0.9760\n",
      "Epoch 51/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0579 - accuracy: 0.9849 - val_loss: 0.0859 - val_accuracy: 0.9752\n",
      "Epoch 52/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0566 - accuracy: 0.9847 - val_loss: 0.0850 - val_accuracy: 0.9762\n",
      "Epoch 53/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0552 - accuracy: 0.9858 - val_loss: 0.0849 - val_accuracy: 0.9766\n",
      "Epoch 54/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0541 - accuracy: 0.9858 - val_loss: 0.0846 - val_accuracy: 0.9762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0530 - accuracy: 0.9861 - val_loss: 0.0838 - val_accuracy: 0.9762\n",
      "Epoch 56/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0519 - accuracy: 0.9866 - val_loss: 0.0841 - val_accuracy: 0.9768\n",
      "Epoch 57/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0507 - accuracy: 0.9871 - val_loss: 0.0822 - val_accuracy: 0.9772\n",
      "Epoch 58/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0497 - accuracy: 0.9874 - val_loss: 0.0820 - val_accuracy: 0.9772\n",
      "Epoch 59/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0486 - accuracy: 0.9875 - val_loss: 0.0815 - val_accuracy: 0.9760\n",
      "Epoch 60/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0476 - accuracy: 0.9881 - val_loss: 0.0830 - val_accuracy: 0.9770\n",
      "Epoch 61/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0468 - accuracy: 0.9881 - val_loss: 0.0811 - val_accuracy: 0.9766\n",
      "Epoch 62/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0458 - accuracy: 0.9887 - val_loss: 0.0800 - val_accuracy: 0.9770\n",
      "Epoch 63/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0448 - accuracy: 0.9889 - val_loss: 0.0816 - val_accuracy: 0.9776\n",
      "Epoch 64/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0438 - accuracy: 0.9893 - val_loss: 0.0801 - val_accuracy: 0.9766\n",
      "Epoch 65/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0431 - accuracy: 0.9894 - val_loss: 0.0797 - val_accuracy: 0.9774\n",
      "Epoch 66/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0421 - accuracy: 0.9895 - val_loss: 0.0787 - val_accuracy: 0.9786\n",
      "Epoch 67/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0412 - accuracy: 0.9900 - val_loss: 0.0781 - val_accuracy: 0.9788\n",
      "Epoch 68/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0405 - accuracy: 0.9902 - val_loss: 0.0776 - val_accuracy: 0.9766\n",
      "Epoch 69/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0397 - accuracy: 0.9902 - val_loss: 0.0791 - val_accuracy: 0.9778\n",
      "Epoch 70/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0389 - accuracy: 0.9905 - val_loss: 0.0775 - val_accuracy: 0.9782\n",
      "Epoch 71/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0381 - accuracy: 0.9907 - val_loss: 0.0777 - val_accuracy: 0.9780\n",
      "Epoch 72/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0375 - accuracy: 0.9909 - val_loss: 0.0773 - val_accuracy: 0.9786\n",
      "Epoch 73/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0367 - accuracy: 0.9912 - val_loss: 0.0763 - val_accuracy: 0.9780\n",
      "Epoch 74/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0359 - accuracy: 0.9915 - val_loss: 0.0765 - val_accuracy: 0.9780\n",
      "Epoch 75/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0353 - accuracy: 0.9917 - val_loss: 0.0761 - val_accuracy: 0.9790\n",
      "Epoch 76/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0345 - accuracy: 0.9920 - val_loss: 0.0765 - val_accuracy: 0.9776\n",
      "Epoch 77/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0339 - accuracy: 0.9921 - val_loss: 0.0750 - val_accuracy: 0.9784\n",
      "Epoch 78/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0333 - accuracy: 0.9922 - val_loss: 0.0763 - val_accuracy: 0.9784\n",
      "Epoch 79/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0327 - accuracy: 0.9927 - val_loss: 0.0751 - val_accuracy: 0.9782\n",
      "Epoch 80/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0321 - accuracy: 0.9925 - val_loss: 0.0753 - val_accuracy: 0.9794\n",
      "Epoch 81/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0314 - accuracy: 0.9929 - val_loss: 0.0752 - val_accuracy: 0.9784\n",
      "Epoch 82/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0308 - accuracy: 0.9932 - val_loss: 0.0749 - val_accuracy: 0.9790\n",
      "Epoch 83/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0302 - accuracy: 0.9932 - val_loss: 0.0751 - val_accuracy: 0.9792\n",
      "Epoch 84/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0297 - accuracy: 0.9933 - val_loss: 0.0740 - val_accuracy: 0.9794\n",
      "Epoch 85/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0291 - accuracy: 0.9937 - val_loss: 0.0744 - val_accuracy: 0.9792\n",
      "Epoch 86/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0286 - accuracy: 0.9939 - val_loss: 0.0740 - val_accuracy: 0.9794\n",
      "Epoch 87/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0281 - accuracy: 0.9941 - val_loss: 0.0749 - val_accuracy: 0.9800\n",
      "Epoch 88/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0275 - accuracy: 0.9941 - val_loss: 0.0741 - val_accuracy: 0.9792\n",
      "Epoch 89/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0270 - accuracy: 0.9943 - val_loss: 0.0748 - val_accuracy: 0.9792\n",
      "Epoch 90/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0265 - accuracy: 0.9945 - val_loss: 0.0736 - val_accuracy: 0.9794\n",
      "Epoch 91/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0260 - accuracy: 0.9949 - val_loss: 0.0758 - val_accuracy: 0.9786\n",
      "Epoch 92/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0255 - accuracy: 0.9949 - val_loss: 0.0752 - val_accuracy: 0.9792\n",
      "Epoch 93/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0252 - accuracy: 0.9949 - val_loss: 0.0734 - val_accuracy: 0.9796\n",
      "Epoch 94/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0247 - accuracy: 0.9951 - val_loss: 0.0735 - val_accuracy: 0.9788\n",
      "Epoch 95/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0242 - accuracy: 0.9953 - val_loss: 0.0734 - val_accuracy: 0.9800\n",
      "Epoch 96/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0238 - accuracy: 0.9956 - val_loss: 0.0736 - val_accuracy: 0.9786\n",
      "Epoch 97/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0233 - accuracy: 0.9955 - val_loss: 0.0726 - val_accuracy: 0.9808\n",
      "Epoch 98/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0229 - accuracy: 0.9959 - val_loss: 0.0733 - val_accuracy: 0.9798\n",
      "Epoch 99/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0225 - accuracy: 0.9959 - val_loss: 0.0739 - val_accuracy: 0.9788\n",
      "Epoch 100/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0221 - accuracy: 0.9961 - val_loss: 0.0730 - val_accuracy: 0.9792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd3a66c9cd0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "n_batches = 100\n",
    "\n",
    "model.fit(X_train, y_train, epochs=n_epochs,\n",
    "          batch_size=n_batches,\n",
    "          shuffle=True,\n",
    "#          validation_split=0.1,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          validation_freq=1,\n",
    "          callbacks=[tensorboard_callback]          \n",
    "         )    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "55000/55000 [==============================] - 1s 25us/sample - loss: 0.7274 - accuracy: 0.8063 - val_loss: 0.4217 - val_accuracy: 0.8908\n",
      "Epoch 2/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.3951 - accuracy: 0.8893 - val_loss: 0.3440 - val_accuracy: 0.9068\n",
      "Epoch 3/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.3448 - accuracy: 0.9018 - val_loss: 0.3101 - val_accuracy: 0.9160\n",
      "Epoch 4/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.3185 - accuracy: 0.9093 - val_loss: 0.2896 - val_accuracy: 0.9206\n",
      "Epoch 5/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.3006 - accuracy: 0.9146 - val_loss: 0.2763 - val_accuracy: 0.9252\n",
      "Epoch 6/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.2868 - accuracy: 0.9185 - val_loss: 0.2654 - val_accuracy: 0.9292\n",
      "Epoch 7/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.2749 - accuracy: 0.9218 - val_loss: 0.2554 - val_accuracy: 0.9320\n",
      "Epoch 8/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.2645 - accuracy: 0.9253 - val_loss: 0.2484 - val_accuracy: 0.9332\n",
      "Epoch 9/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.2549 - accuracy: 0.9280 - val_loss: 0.2377 - val_accuracy: 0.9360\n",
      "Epoch 10/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.2457 - accuracy: 0.9305 - val_loss: 0.2306 - val_accuracy: 0.9378\n",
      "Epoch 11/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.2369 - accuracy: 0.9332 - val_loss: 0.2241 - val_accuracy: 0.9384\n",
      "Epoch 12/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.2287 - accuracy: 0.9358 - val_loss: 0.2170 - val_accuracy: 0.9398\n",
      "Epoch 13/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.2208 - accuracy: 0.9374 - val_loss: 0.2099 - val_accuracy: 0.9420\n",
      "Epoch 14/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.2131 - accuracy: 0.9393 - val_loss: 0.2027 - val_accuracy: 0.9446\n",
      "Epoch 15/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.2060 - accuracy: 0.9414 - val_loss: 0.1971 - val_accuracy: 0.9478\n",
      "Epoch 16/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1991 - accuracy: 0.9432 - val_loss: 0.1911 - val_accuracy: 0.9494\n",
      "Epoch 17/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1925 - accuracy: 0.9451 - val_loss: 0.1846 - val_accuracy: 0.9500\n",
      "Epoch 18/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1861 - accuracy: 0.9470 - val_loss: 0.1794 - val_accuracy: 0.9536\n",
      "Epoch 19/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1802 - accuracy: 0.9489 - val_loss: 0.1743 - val_accuracy: 0.9540\n",
      "Epoch 20/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.1747 - accuracy: 0.9498 - val_loss: 0.1701 - val_accuracy: 0.9550\n",
      "Epoch 21/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1693 - accuracy: 0.9516 - val_loss: 0.1659 - val_accuracy: 0.9558\n",
      "Epoch 22/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1643 - accuracy: 0.9529 - val_loss: 0.1621 - val_accuracy: 0.9572\n",
      "Epoch 23/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.1596 - accuracy: 0.9540 - val_loss: 0.1570 - val_accuracy: 0.9574\n",
      "Epoch 24/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.1551 - accuracy: 0.9554 - val_loss: 0.1527 - val_accuracy: 0.9586\n",
      "Epoch 25/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1509 - accuracy: 0.9565 - val_loss: 0.1498 - val_accuracy: 0.9606\n",
      "Epoch 26/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1468 - accuracy: 0.9578 - val_loss: 0.1468 - val_accuracy: 0.9610\n",
      "Epoch 27/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1430 - accuracy: 0.9587 - val_loss: 0.1431 - val_accuracy: 0.9618\n",
      "Epoch 28/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1395 - accuracy: 0.9600 - val_loss: 0.1403 - val_accuracy: 0.9626\n",
      "Epoch 29/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1360 - accuracy: 0.9610 - val_loss: 0.1372 - val_accuracy: 0.9624\n",
      "Epoch 30/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1327 - accuracy: 0.9622 - val_loss: 0.1347 - val_accuracy: 0.9640\n",
      "Epoch 31/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1295 - accuracy: 0.9628 - val_loss: 0.1318 - val_accuracy: 0.9640\n",
      "Epoch 32/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1265 - accuracy: 0.9637 - val_loss: 0.1295 - val_accuracy: 0.9654\n",
      "Epoch 33/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1238 - accuracy: 0.9644 - val_loss: 0.1280 - val_accuracy: 0.9648\n",
      "Epoch 34/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1208 - accuracy: 0.9655 - val_loss: 0.1258 - val_accuracy: 0.9646\n",
      "Epoch 35/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1182 - accuracy: 0.9662 - val_loss: 0.1236 - val_accuracy: 0.9646\n",
      "Epoch 36/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.1158 - accuracy: 0.9675 - val_loss: 0.1220 - val_accuracy: 0.9648\n",
      "Epoch 37/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1132 - accuracy: 0.9676 - val_loss: 0.1206 - val_accuracy: 0.9670\n",
      "Epoch 38/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.1110 - accuracy: 0.9684 - val_loss: 0.1184 - val_accuracy: 0.9668\n",
      "Epoch 39/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.1087 - accuracy: 0.9691 - val_loss: 0.1158 - val_accuracy: 0.9674\n",
      "Epoch 40/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.1067 - accuracy: 0.9696 - val_loss: 0.1151 - val_accuracy: 0.9668\n",
      "Epoch 41/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1045 - accuracy: 0.9702 - val_loss: 0.1126 - val_accuracy: 0.9684\n",
      "Epoch 42/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.1024 - accuracy: 0.9708 - val_loss: 0.1109 - val_accuracy: 0.9670\n",
      "Epoch 43/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1005 - accuracy: 0.9716 - val_loss: 0.1095 - val_accuracy: 0.9682\n",
      "Epoch 44/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0986 - accuracy: 0.9720 - val_loss: 0.1083 - val_accuracy: 0.9688\n",
      "Epoch 45/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0968 - accuracy: 0.9727 - val_loss: 0.1075 - val_accuracy: 0.9694\n",
      "Epoch 46/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0950 - accuracy: 0.9733 - val_loss: 0.1056 - val_accuracy: 0.9686\n",
      "Epoch 47/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0932 - accuracy: 0.9738 - val_loss: 0.1045 - val_accuracy: 0.9696\n",
      "Epoch 48/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0915 - accuracy: 0.9743 - val_loss: 0.1034 - val_accuracy: 0.9704\n",
      "Epoch 49/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0901 - accuracy: 0.9744 - val_loss: 0.1017 - val_accuracy: 0.9708\n",
      "Epoch 50/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0884 - accuracy: 0.9753 - val_loss: 0.1018 - val_accuracy: 0.9704\n",
      "Epoch 51/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0868 - accuracy: 0.9758 - val_loss: 0.1007 - val_accuracy: 0.9708\n",
      "Epoch 52/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0854 - accuracy: 0.9762 - val_loss: 0.0991 - val_accuracy: 0.9704\n",
      "Epoch 53/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0839 - accuracy: 0.9764 - val_loss: 0.0977 - val_accuracy: 0.9718\n",
      "Epoch 54/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0826 - accuracy: 0.9773 - val_loss: 0.0971 - val_accuracy: 0.9718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0812 - accuracy: 0.9779 - val_loss: 0.0952 - val_accuracy: 0.9714\n",
      "Epoch 56/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0799 - accuracy: 0.9775 - val_loss: 0.0963 - val_accuracy: 0.9716\n",
      "Epoch 57/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0785 - accuracy: 0.9782 - val_loss: 0.0941 - val_accuracy: 0.9732\n",
      "Epoch 58/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0774 - accuracy: 0.9786 - val_loss: 0.0935 - val_accuracy: 0.9718\n",
      "Epoch 59/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0760 - accuracy: 0.9792 - val_loss: 0.0931 - val_accuracy: 0.9720\n",
      "Epoch 60/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0750 - accuracy: 0.9790 - val_loss: 0.0923 - val_accuracy: 0.9728\n",
      "Epoch 61/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0739 - accuracy: 0.9795 - val_loss: 0.0909 - val_accuracy: 0.9732\n",
      "Epoch 62/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0726 - accuracy: 0.9800 - val_loss: 0.0905 - val_accuracy: 0.9734\n",
      "Epoch 63/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0715 - accuracy: 0.9801 - val_loss: 0.0902 - val_accuracy: 0.9730\n",
      "Epoch 64/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0705 - accuracy: 0.9803 - val_loss: 0.0893 - val_accuracy: 0.9738\n",
      "Epoch 65/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0694 - accuracy: 0.9807 - val_loss: 0.0889 - val_accuracy: 0.9738\n",
      "Epoch 66/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0685 - accuracy: 0.9811 - val_loss: 0.0883 - val_accuracy: 0.9732\n",
      "Epoch 67/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0675 - accuracy: 0.9814 - val_loss: 0.0876 - val_accuracy: 0.9736\n",
      "Epoch 68/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0664 - accuracy: 0.9818 - val_loss: 0.0874 - val_accuracy: 0.9742\n",
      "Epoch 69/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0655 - accuracy: 0.9822 - val_loss: 0.0862 - val_accuracy: 0.9744\n",
      "Epoch 70/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0645 - accuracy: 0.9825 - val_loss: 0.0858 - val_accuracy: 0.9758\n",
      "Epoch 71/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0635 - accuracy: 0.9828 - val_loss: 0.0847 - val_accuracy: 0.9752\n",
      "Epoch 72/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0626 - accuracy: 0.9831 - val_loss: 0.0849 - val_accuracy: 0.9746\n",
      "Epoch 73/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0618 - accuracy: 0.9833 - val_loss: 0.0840 - val_accuracy: 0.9748\n",
      "Epoch 74/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0610 - accuracy: 0.9833 - val_loss: 0.0832 - val_accuracy: 0.9752\n",
      "Epoch 75/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0601 - accuracy: 0.9838 - val_loss: 0.0834 - val_accuracy: 0.9754\n",
      "Epoch 76/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0594 - accuracy: 0.9838 - val_loss: 0.0828 - val_accuracy: 0.9748\n",
      "Epoch 77/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0585 - accuracy: 0.9844 - val_loss: 0.0819 - val_accuracy: 0.9756\n",
      "Epoch 78/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0577 - accuracy: 0.9847 - val_loss: 0.0814 - val_accuracy: 0.9762\n",
      "Epoch 79/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0569 - accuracy: 0.9849 - val_loss: 0.0813 - val_accuracy: 0.9766\n",
      "Epoch 80/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0561 - accuracy: 0.9848 - val_loss: 0.0810 - val_accuracy: 0.9760\n",
      "Epoch 81/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0553 - accuracy: 0.9853 - val_loss: 0.0816 - val_accuracy: 0.9762\n",
      "Epoch 82/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0547 - accuracy: 0.9855 - val_loss: 0.0805 - val_accuracy: 0.9766\n",
      "Epoch 83/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0539 - accuracy: 0.9857 - val_loss: 0.0800 - val_accuracy: 0.9764\n",
      "Epoch 84/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0533 - accuracy: 0.9860 - val_loss: 0.0798 - val_accuracy: 0.9766\n",
      "Epoch 85/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0525 - accuracy: 0.9863 - val_loss: 0.0797 - val_accuracy: 0.9770\n",
      "Epoch 86/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0519 - accuracy: 0.9862 - val_loss: 0.0799 - val_accuracy: 0.9770\n",
      "Epoch 87/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0513 - accuracy: 0.9867 - val_loss: 0.0795 - val_accuracy: 0.9764\n",
      "Epoch 88/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0507 - accuracy: 0.9866 - val_loss: 0.0783 - val_accuracy: 0.9774\n",
      "Epoch 89/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0500 - accuracy: 0.9871 - val_loss: 0.0789 - val_accuracy: 0.9768\n",
      "Epoch 90/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0493 - accuracy: 0.9872 - val_loss: 0.0783 - val_accuracy: 0.9762\n",
      "Epoch 91/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0486 - accuracy: 0.9875 - val_loss: 0.0790 - val_accuracy: 0.9764\n",
      "Epoch 92/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0481 - accuracy: 0.9875 - val_loss: 0.0780 - val_accuracy: 0.9766\n",
      "Epoch 93/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0475 - accuracy: 0.9875 - val_loss: 0.0781 - val_accuracy: 0.9776\n",
      "Epoch 94/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0469 - accuracy: 0.9878 - val_loss: 0.0773 - val_accuracy: 0.9766\n",
      "Epoch 95/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0462 - accuracy: 0.9881 - val_loss: 0.0772 - val_accuracy: 0.9764\n",
      "Epoch 96/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0458 - accuracy: 0.9883 - val_loss: 0.0778 - val_accuracy: 0.9776\n",
      "Epoch 97/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0452 - accuracy: 0.9884 - val_loss: 0.0770 - val_accuracy: 0.9774\n",
      "Epoch 98/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0445 - accuracy: 0.9883 - val_loss: 0.0769 - val_accuracy: 0.9776\n",
      "Epoch 99/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0441 - accuracy: 0.9886 - val_loss: 0.0763 - val_accuracy: 0.9768\n",
      "Epoch 100/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0435 - accuracy: 0.9890 - val_loss: 0.0762 - val_accuracy: 0.9774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd3984d79d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelelu.fit(X_train, y_train, epochs=n_epochs,\n",
    "          batch_size=n_batches,\n",
    "          shuffle=True,\n",
    "#          validation_split=0.1,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          validation_freq=1,\n",
    "          callbacks=[tensorboard_callback]          \n",
    "         )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "55000/55000 [==============================] - 1s 26us/sample - loss: 0.9060 - accuracy: 0.7722 - val_loss: 0.4563 - val_accuracy: 0.8832\n",
      "Epoch 2/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.4078 - accuracy: 0.8889 - val_loss: 0.3402 - val_accuracy: 0.9082\n",
      "Epoch 3/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.3357 - accuracy: 0.9062 - val_loss: 0.2987 - val_accuracy: 0.9204\n",
      "Epoch 4/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.2991 - accuracy: 0.9154 - val_loss: 0.2699 - val_accuracy: 0.9250\n",
      "Epoch 5/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.2737 - accuracy: 0.9229 - val_loss: 0.2502 - val_accuracy: 0.9318\n",
      "Epoch 6/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.2540 - accuracy: 0.9279 - val_loss: 0.2348 - val_accuracy: 0.9360\n",
      "Epoch 7/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.2379 - accuracy: 0.9328 - val_loss: 0.2201 - val_accuracy: 0.9400\n",
      "Epoch 8/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.2238 - accuracy: 0.9374 - val_loss: 0.2080 - val_accuracy: 0.9422\n",
      "Epoch 9/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.2115 - accuracy: 0.9402 - val_loss: 0.1979 - val_accuracy: 0.9464\n",
      "Epoch 10/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.2006 - accuracy: 0.9439 - val_loss: 0.1891 - val_accuracy: 0.9488\n",
      "Epoch 11/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1908 - accuracy: 0.9464 - val_loss: 0.1819 - val_accuracy: 0.9492\n",
      "Epoch 12/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.1820 - accuracy: 0.9490 - val_loss: 0.1734 - val_accuracy: 0.9534\n",
      "Epoch 13/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.1737 - accuracy: 0.9513 - val_loss: 0.1683 - val_accuracy: 0.9554\n",
      "Epoch 14/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.1664 - accuracy: 0.9531 - val_loss: 0.1612 - val_accuracy: 0.9572\n",
      "Epoch 15/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1596 - accuracy: 0.9549 - val_loss: 0.1562 - val_accuracy: 0.9586\n",
      "Epoch 16/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1530 - accuracy: 0.9567 - val_loss: 0.1527 - val_accuracy: 0.9592\n",
      "Epoch 17/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1475 - accuracy: 0.9582 - val_loss: 0.1471 - val_accuracy: 0.9618\n",
      "Epoch 18/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1418 - accuracy: 0.9601 - val_loss: 0.1427 - val_accuracy: 0.9616\n",
      "Epoch 19/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.1366 - accuracy: 0.9624 - val_loss: 0.1381 - val_accuracy: 0.9630\n",
      "Epoch 20/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1318 - accuracy: 0.9633 - val_loss: 0.1351 - val_accuracy: 0.9648\n",
      "Epoch 21/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1275 - accuracy: 0.9649 - val_loss: 0.1316 - val_accuracy: 0.9652\n",
      "Epoch 22/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1233 - accuracy: 0.9660 - val_loss: 0.1294 - val_accuracy: 0.9670\n",
      "Epoch 23/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1191 - accuracy: 0.9670 - val_loss: 0.1259 - val_accuracy: 0.9670\n",
      "Epoch 24/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1154 - accuracy: 0.9682 - val_loss: 0.1230 - val_accuracy: 0.9672\n",
      "Epoch 25/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.1118 - accuracy: 0.9694 - val_loss: 0.1204 - val_accuracy: 0.9678\n",
      "Epoch 26/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.1083 - accuracy: 0.9706 - val_loss: 0.1191 - val_accuracy: 0.9688\n",
      "Epoch 27/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1051 - accuracy: 0.9709 - val_loss: 0.1157 - val_accuracy: 0.9694\n",
      "Epoch 28/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1019 - accuracy: 0.9720 - val_loss: 0.1127 - val_accuracy: 0.9692\n",
      "Epoch 29/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0992 - accuracy: 0.9729 - val_loss: 0.1116 - val_accuracy: 0.9698\n",
      "Epoch 30/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0963 - accuracy: 0.9735 - val_loss: 0.1095 - val_accuracy: 0.9714\n",
      "Epoch 31/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0938 - accuracy: 0.9739 - val_loss: 0.1077 - val_accuracy: 0.9718\n",
      "Epoch 32/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0912 - accuracy: 0.9751 - val_loss: 0.1055 - val_accuracy: 0.9718\n",
      "Epoch 33/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0885 - accuracy: 0.9757 - val_loss: 0.1047 - val_accuracy: 0.9726\n",
      "Epoch 34/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0863 - accuracy: 0.9761 - val_loss: 0.1040 - val_accuracy: 0.9724\n",
      "Epoch 35/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0842 - accuracy: 0.9767 - val_loss: 0.1004 - val_accuracy: 0.9726\n",
      "Epoch 36/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0821 - accuracy: 0.9775 - val_loss: 0.0994 - val_accuracy: 0.9730\n",
      "Epoch 37/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0798 - accuracy: 0.9780 - val_loss: 0.0992 - val_accuracy: 0.9728\n",
      "Epoch 38/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0778 - accuracy: 0.9782 - val_loss: 0.0971 - val_accuracy: 0.9728\n",
      "Epoch 39/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0760 - accuracy: 0.9788 - val_loss: 0.0960 - val_accuracy: 0.9746\n",
      "Epoch 40/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0740 - accuracy: 0.9797 - val_loss: 0.0951 - val_accuracy: 0.9738\n",
      "Epoch 41/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0724 - accuracy: 0.9803 - val_loss: 0.0951 - val_accuracy: 0.9728\n",
      "Epoch 42/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0706 - accuracy: 0.9805 - val_loss: 0.0925 - val_accuracy: 0.9748\n",
      "Epoch 43/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0689 - accuracy: 0.9813 - val_loss: 0.0923 - val_accuracy: 0.9748\n",
      "Epoch 44/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0672 - accuracy: 0.9817 - val_loss: 0.0909 - val_accuracy: 0.9748\n",
      "Epoch 45/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0658 - accuracy: 0.9822 - val_loss: 0.0906 - val_accuracy: 0.9752\n",
      "Epoch 46/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0642 - accuracy: 0.9827 - val_loss: 0.0900 - val_accuracy: 0.9752\n",
      "Epoch 47/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0627 - accuracy: 0.9832 - val_loss: 0.0895 - val_accuracy: 0.9758\n",
      "Epoch 48/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0613 - accuracy: 0.9837 - val_loss: 0.0878 - val_accuracy: 0.9760\n",
      "Epoch 49/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0600 - accuracy: 0.9839 - val_loss: 0.0876 - val_accuracy: 0.9752\n",
      "Epoch 50/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0588 - accuracy: 0.9845 - val_loss: 0.0863 - val_accuracy: 0.9752\n",
      "Epoch 51/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0572 - accuracy: 0.9850 - val_loss: 0.0861 - val_accuracy: 0.9770\n",
      "Epoch 52/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0562 - accuracy: 0.9853 - val_loss: 0.0851 - val_accuracy: 0.9764\n",
      "Epoch 53/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0549 - accuracy: 0.9857 - val_loss: 0.0838 - val_accuracy: 0.9766\n",
      "Epoch 54/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0538 - accuracy: 0.9859 - val_loss: 0.0834 - val_accuracy: 0.9766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0526 - accuracy: 0.9864 - val_loss: 0.0832 - val_accuracy: 0.9774\n",
      "Epoch 56/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0515 - accuracy: 0.9869 - val_loss: 0.0822 - val_accuracy: 0.9772\n",
      "Epoch 57/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0503 - accuracy: 0.9871 - val_loss: 0.0823 - val_accuracy: 0.9772\n",
      "Epoch 58/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0495 - accuracy: 0.9873 - val_loss: 0.0824 - val_accuracy: 0.9766\n",
      "Epoch 59/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0482 - accuracy: 0.9880 - val_loss: 0.0816 - val_accuracy: 0.9766\n",
      "Epoch 60/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0473 - accuracy: 0.9879 - val_loss: 0.0809 - val_accuracy: 0.9770\n",
      "Epoch 61/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0463 - accuracy: 0.9884 - val_loss: 0.0807 - val_accuracy: 0.9772\n",
      "Epoch 62/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0453 - accuracy: 0.9889 - val_loss: 0.0808 - val_accuracy: 0.9768\n",
      "Epoch 63/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0445 - accuracy: 0.9887 - val_loss: 0.0808 - val_accuracy: 0.9774\n",
      "Epoch 64/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0435 - accuracy: 0.9893 - val_loss: 0.0797 - val_accuracy: 0.9772\n",
      "Epoch 65/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0427 - accuracy: 0.9894 - val_loss: 0.0784 - val_accuracy: 0.9784\n",
      "Epoch 66/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0418 - accuracy: 0.9895 - val_loss: 0.0776 - val_accuracy: 0.9770\n",
      "Epoch 67/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0410 - accuracy: 0.9897 - val_loss: 0.0780 - val_accuracy: 0.9780\n",
      "Epoch 68/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0402 - accuracy: 0.9902 - val_loss: 0.0781 - val_accuracy: 0.9780\n",
      "Epoch 69/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0393 - accuracy: 0.9904 - val_loss: 0.0777 - val_accuracy: 0.9776\n",
      "Epoch 70/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0386 - accuracy: 0.9907 - val_loss: 0.0767 - val_accuracy: 0.9782\n",
      "Epoch 71/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0378 - accuracy: 0.9911 - val_loss: 0.0768 - val_accuracy: 0.9780\n",
      "Epoch 72/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0371 - accuracy: 0.9909 - val_loss: 0.0766 - val_accuracy: 0.9778\n",
      "Epoch 73/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0364 - accuracy: 0.9912 - val_loss: 0.0761 - val_accuracy: 0.9778\n",
      "Epoch 74/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0357 - accuracy: 0.9916 - val_loss: 0.0758 - val_accuracy: 0.9780\n",
      "Epoch 75/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0350 - accuracy: 0.9918 - val_loss: 0.0758 - val_accuracy: 0.9782\n",
      "Epoch 76/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0343 - accuracy: 0.9921 - val_loss: 0.0765 - val_accuracy: 0.9782\n",
      "Epoch 77/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0337 - accuracy: 0.9922 - val_loss: 0.0753 - val_accuracy: 0.9784\n",
      "Epoch 78/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0330 - accuracy: 0.9924 - val_loss: 0.0748 - val_accuracy: 0.9784\n",
      "Epoch 79/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0324 - accuracy: 0.9925 - val_loss: 0.0756 - val_accuracy: 0.9784\n",
      "Epoch 80/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0318 - accuracy: 0.9929 - val_loss: 0.0744 - val_accuracy: 0.9786\n",
      "Epoch 81/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0312 - accuracy: 0.9930 - val_loss: 0.0747 - val_accuracy: 0.9782\n",
      "Epoch 82/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0306 - accuracy: 0.9931 - val_loss: 0.0747 - val_accuracy: 0.9782\n",
      "Epoch 83/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0300 - accuracy: 0.9935 - val_loss: 0.0749 - val_accuracy: 0.9786\n",
      "Epoch 84/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0294 - accuracy: 0.9934 - val_loss: 0.0734 - val_accuracy: 0.9792\n",
      "Epoch 85/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0289 - accuracy: 0.9937 - val_loss: 0.0743 - val_accuracy: 0.9788\n",
      "Epoch 86/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0282 - accuracy: 0.9941 - val_loss: 0.0745 - val_accuracy: 0.9782\n",
      "Epoch 87/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0278 - accuracy: 0.9943 - val_loss: 0.0749 - val_accuracy: 0.9786\n",
      "Epoch 88/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0273 - accuracy: 0.9942 - val_loss: 0.0732 - val_accuracy: 0.9792\n",
      "Epoch 89/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0268 - accuracy: 0.9947 - val_loss: 0.0733 - val_accuracy: 0.9794\n",
      "Epoch 90/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0263 - accuracy: 0.9945 - val_loss: 0.0749 - val_accuracy: 0.9786\n",
      "Epoch 91/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0259 - accuracy: 0.9947 - val_loss: 0.0733 - val_accuracy: 0.9794\n",
      "Epoch 92/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0254 - accuracy: 0.9949 - val_loss: 0.0733 - val_accuracy: 0.9800\n",
      "Epoch 93/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0249 - accuracy: 0.9952 - val_loss: 0.0732 - val_accuracy: 0.9790\n",
      "Epoch 94/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0245 - accuracy: 0.9953 - val_loss: 0.0733 - val_accuracy: 0.9792\n",
      "Epoch 95/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0240 - accuracy: 0.9955 - val_loss: 0.0732 - val_accuracy: 0.9790\n",
      "Epoch 96/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0236 - accuracy: 0.9955 - val_loss: 0.0727 - val_accuracy: 0.9792\n",
      "Epoch 97/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0231 - accuracy: 0.9958 - val_loss: 0.0733 - val_accuracy: 0.9796\n",
      "Epoch 98/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0228 - accuracy: 0.9958 - val_loss: 0.0737 - val_accuracy: 0.9798\n",
      "Epoch 99/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0223 - accuracy: 0.9962 - val_loss: 0.0739 - val_accuracy: 0.9792\n",
      "Epoch 100/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0219 - accuracy: 0.9963 - val_loss: 0.0730 - val_accuracy: 0.9798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd3a649ec90>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train, y_train, epochs=n_epochs,\n",
    "          batch_size=n_batches,\n",
    "          shuffle=True,\n",
    "#          validation_split=0.1,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          validation_freq=1,\n",
    "          callbacks=[tensorboard_callback]          \n",
    "         )    \n",
    "#with ReLU and He initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "55000/55000 [==============================] - 1s 27us/sample - loss: 1.0445 - accuracy: 0.7488 - val_loss: 0.5006 - val_accuracy: 0.8748\n",
      "Epoch 2/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.4320 - accuracy: 0.8846 - val_loss: 0.3582 - val_accuracy: 0.9032\n",
      "Epoch 3/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.3496 - accuracy: 0.9012 - val_loss: 0.3084 - val_accuracy: 0.9184\n",
      "Epoch 4/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.3118 - accuracy: 0.9116 - val_loss: 0.2814 - val_accuracy: 0.9260\n",
      "Epoch 5/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.2863 - accuracy: 0.9188 - val_loss: 0.2620 - val_accuracy: 0.9288\n",
      "Epoch 6/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.2671 - accuracy: 0.9249 - val_loss: 0.2438 - val_accuracy: 0.9338\n",
      "Epoch 7/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.2510 - accuracy: 0.9290 - val_loss: 0.2319 - val_accuracy: 0.9358\n",
      "Epoch 8/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.2373 - accuracy: 0.9328 - val_loss: 0.2205 - val_accuracy: 0.9384\n",
      "Epoch 9/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.2254 - accuracy: 0.9365 - val_loss: 0.2089 - val_accuracy: 0.9412\n",
      "Epoch 10/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.2144 - accuracy: 0.9394 - val_loss: 0.2023 - val_accuracy: 0.9422\n",
      "Epoch 11/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.2046 - accuracy: 0.9423 - val_loss: 0.1903 - val_accuracy: 0.9470\n",
      "Epoch 12/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.1955 - accuracy: 0.9447 - val_loss: 0.1844 - val_accuracy: 0.9502\n",
      "Epoch 13/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.1873 - accuracy: 0.9473 - val_loss: 0.1776 - val_accuracy: 0.9514\n",
      "Epoch 14/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.1793 - accuracy: 0.9492 - val_loss: 0.1721 - val_accuracy: 0.9530\n",
      "Epoch 15/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.1725 - accuracy: 0.9507 - val_loss: 0.1648 - val_accuracy: 0.9538\n",
      "Epoch 16/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.1658 - accuracy: 0.9532 - val_loss: 0.1601 - val_accuracy: 0.9556\n",
      "Epoch 17/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.1594 - accuracy: 0.9549 - val_loss: 0.1557 - val_accuracy: 0.9550\n",
      "Epoch 18/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1539 - accuracy: 0.9566 - val_loss: 0.1499 - val_accuracy: 0.9588\n",
      "Epoch 19/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.1484 - accuracy: 0.9581 - val_loss: 0.1456 - val_accuracy: 0.9604\n",
      "Epoch 20/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1432 - accuracy: 0.9592 - val_loss: 0.1426 - val_accuracy: 0.9610\n",
      "Epoch 21/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.1384 - accuracy: 0.9608 - val_loss: 0.1394 - val_accuracy: 0.9616\n",
      "Epoch 22/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.1339 - accuracy: 0.9619 - val_loss: 0.1351 - val_accuracy: 0.9618\n",
      "Epoch 23/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1294 - accuracy: 0.9640 - val_loss: 0.1302 - val_accuracy: 0.9638\n",
      "Epoch 24/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.1256 - accuracy: 0.9645 - val_loss: 0.1276 - val_accuracy: 0.9652\n",
      "Epoch 25/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.1216 - accuracy: 0.9656 - val_loss: 0.1262 - val_accuracy: 0.9644\n",
      "Epoch 26/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.1177 - accuracy: 0.9668 - val_loss: 0.1238 - val_accuracy: 0.9654\n",
      "Epoch 27/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.1143 - accuracy: 0.9678 - val_loss: 0.1196 - val_accuracy: 0.9668\n",
      "Epoch 28/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1111 - accuracy: 0.9691 - val_loss: 0.1179 - val_accuracy: 0.9678\n",
      "Epoch 29/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1079 - accuracy: 0.9698 - val_loss: 0.1156 - val_accuracy: 0.9672\n",
      "Epoch 30/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1047 - accuracy: 0.9704 - val_loss: 0.1135 - val_accuracy: 0.9674\n",
      "Epoch 31/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1020 - accuracy: 0.9717 - val_loss: 0.1103 - val_accuracy: 0.9686\n",
      "Epoch 32/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0993 - accuracy: 0.9721 - val_loss: 0.1077 - val_accuracy: 0.9704\n",
      "Epoch 33/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0966 - accuracy: 0.9734 - val_loss: 0.1082 - val_accuracy: 0.9702\n",
      "Epoch 34/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0938 - accuracy: 0.9740 - val_loss: 0.1051 - val_accuracy: 0.9716\n",
      "Epoch 35/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0915 - accuracy: 0.9747 - val_loss: 0.1027 - val_accuracy: 0.9714\n",
      "Epoch 36/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0891 - accuracy: 0.9754 - val_loss: 0.1018 - val_accuracy: 0.9720\n",
      "Epoch 37/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0870 - accuracy: 0.9763 - val_loss: 0.1018 - val_accuracy: 0.9702\n",
      "Epoch 38/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0847 - accuracy: 0.9766 - val_loss: 0.0983 - val_accuracy: 0.9724\n",
      "Epoch 39/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0826 - accuracy: 0.9774 - val_loss: 0.0968 - val_accuracy: 0.9724\n",
      "Epoch 40/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0807 - accuracy: 0.9780 - val_loss: 0.0972 - val_accuracy: 0.9730\n",
      "Epoch 41/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0787 - accuracy: 0.9787 - val_loss: 0.0947 - val_accuracy: 0.9724\n",
      "Epoch 42/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0767 - accuracy: 0.9792 - val_loss: 0.0942 - val_accuracy: 0.9732\n",
      "Epoch 43/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0749 - accuracy: 0.9797 - val_loss: 0.0924 - val_accuracy: 0.9740\n",
      "Epoch 44/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0732 - accuracy: 0.9807 - val_loss: 0.0910 - val_accuracy: 0.9744\n",
      "Epoch 45/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0715 - accuracy: 0.9812 - val_loss: 0.0897 - val_accuracy: 0.9748\n",
      "Epoch 46/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0699 - accuracy: 0.9808 - val_loss: 0.0887 - val_accuracy: 0.9752\n",
      "Epoch 47/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0683 - accuracy: 0.9818 - val_loss: 0.0893 - val_accuracy: 0.9750\n",
      "Epoch 48/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0667 - accuracy: 0.9822 - val_loss: 0.0866 - val_accuracy: 0.9752\n",
      "Epoch 49/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0653 - accuracy: 0.9826 - val_loss: 0.0853 - val_accuracy: 0.9766\n",
      "Epoch 50/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0637 - accuracy: 0.9832 - val_loss: 0.0846 - val_accuracy: 0.9772\n",
      "Epoch 51/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0623 - accuracy: 0.9838 - val_loss: 0.0841 - val_accuracy: 0.9762\n",
      "Epoch 52/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0610 - accuracy: 0.9837 - val_loss: 0.0830 - val_accuracy: 0.9770\n",
      "Epoch 53/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0596 - accuracy: 0.9844 - val_loss: 0.0824 - val_accuracy: 0.9774\n",
      "Epoch 54/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0583 - accuracy: 0.9846 - val_loss: 0.0815 - val_accuracy: 0.9766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0571 - accuracy: 0.9851 - val_loss: 0.0811 - val_accuracy: 0.9776\n",
      "Epoch 56/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0558 - accuracy: 0.9855 - val_loss: 0.0802 - val_accuracy: 0.9762\n",
      "Epoch 57/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0546 - accuracy: 0.9857 - val_loss: 0.0796 - val_accuracy: 0.9778\n",
      "Epoch 58/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0536 - accuracy: 0.9862 - val_loss: 0.0790 - val_accuracy: 0.9776\n",
      "Epoch 59/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0524 - accuracy: 0.9865 - val_loss: 0.0784 - val_accuracy: 0.9778\n",
      "Epoch 60/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0514 - accuracy: 0.9869 - val_loss: 0.0782 - val_accuracy: 0.9776\n",
      "Epoch 61/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0501 - accuracy: 0.9873 - val_loss: 0.0770 - val_accuracy: 0.9780\n",
      "Epoch 62/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0493 - accuracy: 0.9873 - val_loss: 0.0775 - val_accuracy: 0.9782\n",
      "Epoch 63/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0482 - accuracy: 0.9876 - val_loss: 0.0768 - val_accuracy: 0.9786\n",
      "Epoch 64/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0472 - accuracy: 0.9880 - val_loss: 0.0752 - val_accuracy: 0.9786\n",
      "Epoch 65/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0463 - accuracy: 0.9880 - val_loss: 0.0755 - val_accuracy: 0.9784\n",
      "Epoch 66/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0452 - accuracy: 0.9885 - val_loss: 0.0754 - val_accuracy: 0.9788\n",
      "Epoch 67/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0443 - accuracy: 0.9890 - val_loss: 0.0743 - val_accuracy: 0.9784\n",
      "Epoch 68/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0435 - accuracy: 0.9892 - val_loss: 0.0742 - val_accuracy: 0.9788\n",
      "Epoch 69/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0427 - accuracy: 0.9893 - val_loss: 0.0736 - val_accuracy: 0.9784\n",
      "Epoch 70/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0418 - accuracy: 0.9897 - val_loss: 0.0739 - val_accuracy: 0.9786\n",
      "Epoch 71/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0410 - accuracy: 0.9897 - val_loss: 0.0726 - val_accuracy: 0.9794\n",
      "Epoch 72/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0402 - accuracy: 0.9901 - val_loss: 0.0723 - val_accuracy: 0.9792\n",
      "Epoch 73/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0394 - accuracy: 0.9903 - val_loss: 0.0721 - val_accuracy: 0.9796\n",
      "Epoch 74/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0386 - accuracy: 0.9905 - val_loss: 0.0715 - val_accuracy: 0.9782\n",
      "Epoch 75/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0378 - accuracy: 0.9910 - val_loss: 0.0720 - val_accuracy: 0.9792\n",
      "Epoch 76/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0371 - accuracy: 0.9909 - val_loss: 0.0738 - val_accuracy: 0.9790\n",
      "Epoch 77/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0365 - accuracy: 0.9913 - val_loss: 0.0713 - val_accuracy: 0.9790\n",
      "Epoch 78/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0356 - accuracy: 0.9916 - val_loss: 0.0725 - val_accuracy: 0.9788\n",
      "Epoch 79/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0350 - accuracy: 0.9917 - val_loss: 0.0722 - val_accuracy: 0.9790\n",
      "Epoch 80/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0344 - accuracy: 0.9919 - val_loss: 0.0707 - val_accuracy: 0.9796\n",
      "Epoch 81/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0336 - accuracy: 0.9921 - val_loss: 0.0709 - val_accuracy: 0.9792\n",
      "Epoch 82/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0331 - accuracy: 0.9923 - val_loss: 0.0695 - val_accuracy: 0.9788\n",
      "Epoch 83/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0324 - accuracy: 0.9923 - val_loss: 0.0688 - val_accuracy: 0.9794\n",
      "Epoch 84/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0318 - accuracy: 0.9928 - val_loss: 0.0689 - val_accuracy: 0.9794\n",
      "Epoch 85/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0311 - accuracy: 0.9929 - val_loss: 0.0694 - val_accuracy: 0.9800\n",
      "Epoch 86/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0306 - accuracy: 0.9932 - val_loss: 0.0687 - val_accuracy: 0.9796\n",
      "Epoch 87/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0299 - accuracy: 0.9929 - val_loss: 0.0698 - val_accuracy: 0.9800\n",
      "Epoch 88/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0294 - accuracy: 0.9933 - val_loss: 0.0680 - val_accuracy: 0.9798\n",
      "Epoch 89/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0288 - accuracy: 0.9933 - val_loss: 0.0676 - val_accuracy: 0.9812\n",
      "Epoch 90/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0284 - accuracy: 0.9935 - val_loss: 0.0674 - val_accuracy: 0.9802\n",
      "Epoch 91/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0278 - accuracy: 0.9941 - val_loss: 0.0693 - val_accuracy: 0.9806\n",
      "Epoch 92/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0273 - accuracy: 0.9939 - val_loss: 0.0677 - val_accuracy: 0.9806\n",
      "Epoch 93/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0267 - accuracy: 0.9940 - val_loss: 0.0687 - val_accuracy: 0.9796\n",
      "Epoch 94/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0262 - accuracy: 0.9944 - val_loss: 0.0675 - val_accuracy: 0.9810\n",
      "Epoch 95/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0258 - accuracy: 0.9944 - val_loss: 0.0670 - val_accuracy: 0.9812\n",
      "Epoch 96/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0253 - accuracy: 0.9948 - val_loss: 0.0684 - val_accuracy: 0.9802\n",
      "Epoch 97/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0248 - accuracy: 0.9949 - val_loss: 0.0669 - val_accuracy: 0.9806\n",
      "Epoch 98/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0244 - accuracy: 0.9951 - val_loss: 0.0669 - val_accuracy: 0.9812\n",
      "Epoch 99/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0240 - accuracy: 0.9950 - val_loss: 0.0662 - val_accuracy: 0.9812\n",
      "Epoch 100/100\n",
      "55000/55000 [==============================] - 1s 24us/sample - loss: 0.0236 - accuracy: 0.9952 - val_loss: 0.0672 - val_accuracy: 0.9810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd3a637dbd0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(X_train, y_train, epochs=n_epochs,\n",
    "          batch_size=n_batches,\n",
    "          shuffle=True,\n",
    "#          validation_split=0.1,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          validation_freq=1,\n",
    "          callbacks=[tensorboard_callback]          \n",
    "         )    \n",
    "#with Leaky ReLU without He initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "55000/55000 [==============================] - 1s 26us/sample - loss: 1.0481 - accuracy: 0.7600 - val_loss: 0.4883 - val_accuracy: 0.8828\n",
      "Epoch 2/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.4241 - accuracy: 0.8859 - val_loss: 0.3480 - val_accuracy: 0.9044\n",
      "Epoch 3/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.3429 - accuracy: 0.9032 - val_loss: 0.2990 - val_accuracy: 0.9158\n",
      "Epoch 4/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.3043 - accuracy: 0.9140 - val_loss: 0.2708 - val_accuracy: 0.9248\n",
      "Epoch 5/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.2782 - accuracy: 0.9212 - val_loss: 0.2487 - val_accuracy: 0.9312\n",
      "Epoch 6/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.2585 - accuracy: 0.9267 - val_loss: 0.2330 - val_accuracy: 0.9362\n",
      "Epoch 7/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.2423 - accuracy: 0.9315 - val_loss: 0.2183 - val_accuracy: 0.9408\n",
      "Epoch 8/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.2287 - accuracy: 0.9357 - val_loss: 0.2069 - val_accuracy: 0.9424\n",
      "Epoch 9/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.2167 - accuracy: 0.9389 - val_loss: 0.1969 - val_accuracy: 0.9448\n",
      "Epoch 10/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.2062 - accuracy: 0.9420 - val_loss: 0.1896 - val_accuracy: 0.9478\n",
      "Epoch 11/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.1967 - accuracy: 0.9444 - val_loss: 0.1794 - val_accuracy: 0.9518\n",
      "Epoch 12/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1879 - accuracy: 0.9469 - val_loss: 0.1724 - val_accuracy: 0.9534\n",
      "Epoch 13/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1802 - accuracy: 0.9495 - val_loss: 0.1672 - val_accuracy: 0.9556\n",
      "Epoch 14/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.1726 - accuracy: 0.9512 - val_loss: 0.1618 - val_accuracy: 0.9568\n",
      "Epoch 15/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1662 - accuracy: 0.9532 - val_loss: 0.1554 - val_accuracy: 0.9580\n",
      "Epoch 16/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.1599 - accuracy: 0.9547 - val_loss: 0.1505 - val_accuracy: 0.9606\n",
      "Epoch 17/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.1541 - accuracy: 0.9564 - val_loss: 0.1469 - val_accuracy: 0.9590\n",
      "Epoch 18/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1487 - accuracy: 0.9579 - val_loss: 0.1418 - val_accuracy: 0.9624\n",
      "Epoch 19/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.1433 - accuracy: 0.9595 - val_loss: 0.1379 - val_accuracy: 0.9622\n",
      "Epoch 20/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.1384 - accuracy: 0.9609 - val_loss: 0.1347 - val_accuracy: 0.9642\n",
      "Epoch 21/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.1341 - accuracy: 0.9622 - val_loss: 0.1307 - val_accuracy: 0.9652\n",
      "Epoch 22/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1296 - accuracy: 0.9636 - val_loss: 0.1286 - val_accuracy: 0.9670\n",
      "Epoch 23/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1255 - accuracy: 0.9649 - val_loss: 0.1257 - val_accuracy: 0.9674\n",
      "Epoch 24/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.1217 - accuracy: 0.9659 - val_loss: 0.1214 - val_accuracy: 0.9678\n",
      "Epoch 25/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.1180 - accuracy: 0.9673 - val_loss: 0.1202 - val_accuracy: 0.9690\n",
      "Epoch 26/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1144 - accuracy: 0.9687 - val_loss: 0.1176 - val_accuracy: 0.9684\n",
      "Epoch 27/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.1111 - accuracy: 0.9694 - val_loss: 0.1156 - val_accuracy: 0.9696\n",
      "Epoch 28/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.1077 - accuracy: 0.9702 - val_loss: 0.1128 - val_accuracy: 0.9704\n",
      "Epoch 29/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.1048 - accuracy: 0.9706 - val_loss: 0.1107 - val_accuracy: 0.9708\n",
      "Epoch 30/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.1017 - accuracy: 0.9719 - val_loss: 0.1088 - val_accuracy: 0.9710\n",
      "Epoch 31/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0991 - accuracy: 0.9729 - val_loss: 0.1070 - val_accuracy: 0.9724\n",
      "Epoch 32/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0962 - accuracy: 0.9736 - val_loss: 0.1045 - val_accuracy: 0.9728\n",
      "Epoch 33/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0938 - accuracy: 0.9742 - val_loss: 0.1031 - val_accuracy: 0.9732\n",
      "Epoch 34/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0912 - accuracy: 0.9755 - val_loss: 0.1022 - val_accuracy: 0.9730\n",
      "Epoch 35/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0888 - accuracy: 0.9758 - val_loss: 0.1005 - val_accuracy: 0.9722\n",
      "Epoch 36/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0864 - accuracy: 0.9768 - val_loss: 0.0993 - val_accuracy: 0.9730\n",
      "Epoch 37/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0843 - accuracy: 0.9769 - val_loss: 0.0972 - val_accuracy: 0.9738\n",
      "Epoch 38/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0820 - accuracy: 0.9774 - val_loss: 0.0969 - val_accuracy: 0.9742\n",
      "Epoch 39/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0800 - accuracy: 0.9784 - val_loss: 0.0949 - val_accuracy: 0.9756\n",
      "Epoch 40/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0781 - accuracy: 0.9790 - val_loss: 0.0933 - val_accuracy: 0.9740\n",
      "Epoch 41/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0761 - accuracy: 0.9796 - val_loss: 0.0927 - val_accuracy: 0.9742\n",
      "Epoch 42/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0744 - accuracy: 0.9802 - val_loss: 0.0900 - val_accuracy: 0.9746\n",
      "Epoch 43/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0725 - accuracy: 0.9806 - val_loss: 0.0889 - val_accuracy: 0.9756\n",
      "Epoch 44/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0708 - accuracy: 0.9811 - val_loss: 0.0879 - val_accuracy: 0.9762\n",
      "Epoch 45/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0692 - accuracy: 0.9815 - val_loss: 0.0881 - val_accuracy: 0.9748\n",
      "Epoch 46/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0675 - accuracy: 0.9821 - val_loss: 0.0872 - val_accuracy: 0.9754\n",
      "Epoch 47/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0659 - accuracy: 0.9822 - val_loss: 0.0856 - val_accuracy: 0.9756\n",
      "Epoch 48/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0643 - accuracy: 0.9829 - val_loss: 0.0855 - val_accuracy: 0.9756\n",
      "Epoch 49/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0630 - accuracy: 0.9831 - val_loss: 0.0840 - val_accuracy: 0.9764\n",
      "Epoch 50/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0615 - accuracy: 0.9838 - val_loss: 0.0828 - val_accuracy: 0.9774\n",
      "Epoch 51/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0600 - accuracy: 0.9841 - val_loss: 0.0834 - val_accuracy: 0.9772\n",
      "Epoch 52/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0587 - accuracy: 0.9845 - val_loss: 0.0817 - val_accuracy: 0.9766\n",
      "Epoch 53/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0575 - accuracy: 0.9850 - val_loss: 0.0801 - val_accuracy: 0.9780\n",
      "Epoch 54/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0562 - accuracy: 0.9850 - val_loss: 0.0803 - val_accuracy: 0.9776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0549 - accuracy: 0.9858 - val_loss: 0.0807 - val_accuracy: 0.9770\n",
      "Epoch 56/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0538 - accuracy: 0.9860 - val_loss: 0.0800 - val_accuracy: 0.9770\n",
      "Epoch 57/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0526 - accuracy: 0.9863 - val_loss: 0.0781 - val_accuracy: 0.9770\n",
      "Epoch 58/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0514 - accuracy: 0.9867 - val_loss: 0.0777 - val_accuracy: 0.9786\n",
      "Epoch 59/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0504 - accuracy: 0.9865 - val_loss: 0.0779 - val_accuracy: 0.9774\n",
      "Epoch 60/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0492 - accuracy: 0.9872 - val_loss: 0.0776 - val_accuracy: 0.9770\n",
      "Epoch 61/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0483 - accuracy: 0.9876 - val_loss: 0.0770 - val_accuracy: 0.9786\n",
      "Epoch 62/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0473 - accuracy: 0.9880 - val_loss: 0.0769 - val_accuracy: 0.9780\n",
      "Epoch 63/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0462 - accuracy: 0.9881 - val_loss: 0.0755 - val_accuracy: 0.9776\n",
      "Epoch 64/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0454 - accuracy: 0.9883 - val_loss: 0.0758 - val_accuracy: 0.9784\n",
      "Epoch 65/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0443 - accuracy: 0.9888 - val_loss: 0.0753 - val_accuracy: 0.9782\n",
      "Epoch 66/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0435 - accuracy: 0.9891 - val_loss: 0.0748 - val_accuracy: 0.9804\n",
      "Epoch 67/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0426 - accuracy: 0.9893 - val_loss: 0.0742 - val_accuracy: 0.9782\n",
      "Epoch 68/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0417 - accuracy: 0.9896 - val_loss: 0.0739 - val_accuracy: 0.9802\n",
      "Epoch 69/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0410 - accuracy: 0.9899 - val_loss: 0.0734 - val_accuracy: 0.9800\n",
      "Epoch 70/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0401 - accuracy: 0.9901 - val_loss: 0.0727 - val_accuracy: 0.9794\n",
      "Epoch 71/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0393 - accuracy: 0.9905 - val_loss: 0.0726 - val_accuracy: 0.9800\n",
      "Epoch 72/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0385 - accuracy: 0.9904 - val_loss: 0.0727 - val_accuracy: 0.9792\n",
      "Epoch 73/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0377 - accuracy: 0.9914 - val_loss: 0.0725 - val_accuracy: 0.9798\n",
      "Epoch 74/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0371 - accuracy: 0.9913 - val_loss: 0.0728 - val_accuracy: 0.9794\n",
      "Epoch 75/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0363 - accuracy: 0.9915 - val_loss: 0.0719 - val_accuracy: 0.9806\n",
      "Epoch 76/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0356 - accuracy: 0.9918 - val_loss: 0.0712 - val_accuracy: 0.9800\n",
      "Epoch 77/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0349 - accuracy: 0.9918 - val_loss: 0.0719 - val_accuracy: 0.9798\n",
      "Epoch 78/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0341 - accuracy: 0.9923 - val_loss: 0.0721 - val_accuracy: 0.9798\n",
      "Epoch 79/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0336 - accuracy: 0.9923 - val_loss: 0.0712 - val_accuracy: 0.9790\n",
      "Epoch 80/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0329 - accuracy: 0.9924 - val_loss: 0.0715 - val_accuracy: 0.9792\n",
      "Epoch 81/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0323 - accuracy: 0.9928 - val_loss: 0.0708 - val_accuracy: 0.9796\n",
      "Epoch 82/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0317 - accuracy: 0.9927 - val_loss: 0.0705 - val_accuracy: 0.9790\n",
      "Epoch 83/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0311 - accuracy: 0.9931 - val_loss: 0.0710 - val_accuracy: 0.9790\n",
      "Epoch 84/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0305 - accuracy: 0.9935 - val_loss: 0.0705 - val_accuracy: 0.9800\n",
      "Epoch 85/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0300 - accuracy: 0.9937 - val_loss: 0.0703 - val_accuracy: 0.9798\n",
      "Epoch 86/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0294 - accuracy: 0.9939 - val_loss: 0.0700 - val_accuracy: 0.9794\n",
      "Epoch 87/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0288 - accuracy: 0.9938 - val_loss: 0.0703 - val_accuracy: 0.9796\n",
      "Epoch 88/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0283 - accuracy: 0.9940 - val_loss: 0.0703 - val_accuracy: 0.9792\n",
      "Epoch 89/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0278 - accuracy: 0.9941 - val_loss: 0.0690 - val_accuracy: 0.9794\n",
      "Epoch 90/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0273 - accuracy: 0.9944 - val_loss: 0.0691 - val_accuracy: 0.9802\n",
      "Epoch 91/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0268 - accuracy: 0.9946 - val_loss: 0.0691 - val_accuracy: 0.9796\n",
      "Epoch 92/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0263 - accuracy: 0.9948 - val_loss: 0.0693 - val_accuracy: 0.9792\n",
      "Epoch 93/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0259 - accuracy: 0.9948 - val_loss: 0.0694 - val_accuracy: 0.9798\n",
      "Epoch 94/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0254 - accuracy: 0.9951 - val_loss: 0.0697 - val_accuracy: 0.9786\n",
      "Epoch 95/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0250 - accuracy: 0.9951 - val_loss: 0.0690 - val_accuracy: 0.9800\n",
      "Epoch 96/100\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.0245 - accuracy: 0.9953 - val_loss: 0.0694 - val_accuracy: 0.9794\n",
      "Epoch 97/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0240 - accuracy: 0.9955 - val_loss: 0.0689 - val_accuracy: 0.9802\n",
      "Epoch 98/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0236 - accuracy: 0.9959 - val_loss: 0.0688 - val_accuracy: 0.9800\n",
      "Epoch 99/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0232 - accuracy: 0.9958 - val_loss: 0.0683 - val_accuracy: 0.9798\n",
      "Epoch 100/100\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.0227 - accuracy: 0.9959 - val_loss: 0.0694 - val_accuracy: 0.9790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd3987a8a10>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(X_train, y_train, epochs=n_epochs,\n",
    "          batch_size=n_batches,\n",
    "          shuffle=True,\n",
    "#          validation_split=0.1,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          validation_freq=1,\n",
    "          callbacks=[tensorboard_callback]          \n",
    "         )    \n",
    "#with ReLU without He initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Practice]\n",
    "**Train the above network with various alpha values and compare the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 0s - loss: 0.0694 - accuracy: 0.9783\n",
      "10000/10000 - 0s - loss: 0.0701 - accuracy: 0.9790\n",
      "10000/10000 - 0s - loss: 0.0710 - accuracy: 0.9791\n",
      "10000/10000 - 0s - loss: 0.0704 - accuracy: 0.9775\n",
      "10000/10000 - 0s - loss: 0.0784 - accuracy: 0.9757\n",
      "\n",
      "Test Accuracy: 0.9783\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)\n",
    "test_loss2, test_acc2 = model2.evaluate(X_test,  y_test, verbose=2)\n",
    "test_loss3, test_acc3 = model3.evaluate(X_test,  y_test, verbose=2)\n",
    "test_loss4, test_acc4 = model4.evaluate(X_test,  y_test, verbose=2)\n",
    "test_loss4, test_acc4 = modelelu.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print('\\nTest Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: logs_11/model/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_imported = keras.models.load_model(log_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 1s - loss: 0.1991 - accuracy: 0.9434\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_imported.evaluate(X_test,  y_test, verbose=2) # required for executing summary method\n",
    "model_imported.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Practice]\n",
    "**Train the above network until val_accuracy becomes larger than 0.99 or n_epoch=100, and check the test accuracy**\n",
    "\n",
    "**1) with leaky ReLU and without He initialization,**\n",
    "**2) with ReLU and He initialization,**\n",
    "**3) with leaky ReLU and He initialization.**\n",
    "\n",
    "**Compare the results with ReLU and without He initialization (obtained in chap. 10)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elu(z, alpha=1):\n",
    "    return np.where(z < 0, alpha * (np.exp(z) - 1), z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure elu_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, elu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1, -1], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(r\"ELU activation function ($\\alpha=1$)\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "\n",
    "save_fig(\"elu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing ELU in TensorFlow is trivial, just specify the activation function when building each layer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Practice]\n",
    "**Train the above network with ELU activation and compare the results**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SELU (Scaled ELU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This activation function was proposed in this [great paper](https://arxiv.org/pdf/1706.02515.pdf) by GÃ¼nter Klambauer, Thomas Unterthiner and Andreas Mayr, published in June 2017. During training, a neural network composed exclusively of a stack of dense layers using the SELU activation function and LeCun initialization will self-normalize: the output of each layer will tend to preserve the same mean and variance during training, which solves the vanishing/exploding gradients problem. As a result, this activation function outperforms the other activation functions very significantly for such neural nets, so you should really try it out. Unfortunately, the self-normalizing property of the SELU activation function is easily broken: you cannot use â„“<sub>1</sub> or â„“<sub>2</sub> regularization, regular dropout, max-norm, skip connections or other non-sequential topologies (so recurrent neural networks won't self-normalize). However, in practice it works quite well with sequential CNNs. If you break self-normalization, SELU will not necessarily outperform other activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import erfc\n",
    "\n",
    "# alpha and scale to self normalize with mean 0 and standard deviation 1\n",
    "# (see equation 14 in the paper):\n",
    "alpha_0_1 = -np.sqrt(2 / np.pi) / (erfc(1/np.sqrt(2)) * np.exp(1/2) - 1)\n",
    "scale_0_1 = (1 - erfc(1 / np.sqrt(2)) * np.sqrt(np.e)) * np.sqrt(2 * np.pi) * (2 * erfc(np.sqrt(2))*np.e**2 + np.pi*erfc(1/np.sqrt(2))**2*np.e - 2*(2+np.pi)*erfc(1/np.sqrt(2))*np.sqrt(np.e)+np.pi+2)**(-1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selu(z, scale=scale_0_1, alpha=alpha_0_1):\n",
    "    return scale * elu(z, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure selu_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, selu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1.758, -1.758], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(r\"SELU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "\n",
    "save_fig(\"selu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the SELU hyperparameters (`scale` and `alpha`) are tuned in such a way that the mean output of each neuron remains close to 0, and the standard deviation remains close to 1 (assuming the inputs are standardized with mean 0 and standard deviation 1 too). Using this activation function, even a 1,000 layer deep neural network preserves roughly mean 0 and standard deviation 1 across all layers, avoiding the exploding/vanishing gradients problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: mean -0.00, std deviation 1.00\n",
      "Layer 100: mean 0.02, std deviation 0.96\n",
      "Layer 200: mean 0.01, std deviation 0.90\n",
      "Layer 300: mean -0.02, std deviation 0.92\n",
      "Layer 400: mean 0.05, std deviation 0.89\n",
      "Layer 500: mean 0.01, std deviation 0.93\n",
      "Layer 600: mean 0.02, std deviation 0.92\n",
      "Layer 700: mean -0.02, std deviation 0.90\n",
      "Layer 800: mean 0.05, std deviation 0.83\n",
      "Layer 900: mean 0.02, std deviation 1.00\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "Z = np.random.normal(size=(500, 100)) # standardized inputs\n",
    "for layer in range(1000):\n",
    "    W = np.random.normal(size=(100, 100), scale=np.sqrt(1 / 100)) # LeCun initialization\n",
    "    Z = selu(np.dot(Z, W))\n",
    "    means = np.mean(Z, axis=0).mean()\n",
    "    stds = np.std(Z, axis=0).mean()\n",
    "    if layer % 100 == 0:\n",
    "        print(\"Layer {}: mean {:.2f}, std deviation {:.2f}\".format(layer, means, stds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `tf.nn.selu()` function was added in TensorFlow 1.4. For earlier versions, you can use the following implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selu(z, scale=alpha_0_1, alpha=scale_0_1):\n",
    "    return scale * tf.where(z >= 0.0, z, alpha * tf.nn.elu(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the SELU activation function cannot be used along with regular Dropout (this would cancel the SELU activation function's self-normalizing property). Fortunately, there is a Dropout variant called Alpha Dropout proposed in the same paper. It is available in `tf.contrib.nn.alpha_dropout()` since TF 1.4 (or check out [this implementation](https://github.com/bioinf-jku/SNNs/blob/master/selu.py) by the Institute of Bioinformatics, Johannes Kepler University Linz)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a neural net for MNIST using the SELU activation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "n_epochs = 5\n",
    "batch_size = 50\n",
    "\n",
    "model1 = keras.Sequential([\n",
    "    keras.layers.Dense(n_hidden1, kernel_initializer=he_init, activation=tf.nn.selu),\n",
    "    keras.layers.Dense(n_hidden2, kernel_initializer=he_init, activation=tf.nn.selu),\n",
    "    keras.layers.Dense(n_outputs, kernel_initializer=he_init, activation='softmax')\n",
    "])    \n",
    "\n",
    "model1.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "log_dir=\"logs_11/model1/\"\n",
    "\n",
    "file_writer = tf.summary.create_file_writer(log_dir + \"/metrics\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, \n",
    "                                                      update_freq=10, profile_batch = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train it. Do not forget to scale the inputs to mean 0 and standard deviation 1: Already done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 1s 25us/sample - loss: 0.5790 - accuracy: 0.8344 - val_loss: 0.3622 - val_accuracy: 0.9006\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.3511 - accuracy: 0.8999 - val_loss: 0.3051 - val_accuracy: 0.9186\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.3119 - accuracy: 0.9109 - val_loss: 0.2823 - val_accuracy: 0.9234\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.2891 - accuracy: 0.9174 - val_loss: 0.2645 - val_accuracy: 0.9290\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.2718 - accuracy: 0.9227 - val_loss: 0.2512 - val_accuracy: 0.9316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd3980b7610>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, y_train, epochs=n_epochs,\n",
    "          batch_size=n_batches,\n",
    "          shuffle=True,\n",
    "#          validation_split=0.1,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          validation_freq=1,\n",
    "          callbacks=[tensorboard_callback]          \n",
    "         )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bigcloud/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: logs_11/model1/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model1, log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 0s - loss: 0.2567 - accuracy: 0.9270\n",
      "\n",
      "Test Accuracy: 0.927\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model1.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print('\\nTest Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Model1 for another 5 epoch. Watch the loss values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.2575 - accuracy: 0.9274 - val_loss: 0.2434 - val_accuracy: 0.9336\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 1s 22us/sample - loss: 0.2448 - accuracy: 0.9309 - val_loss: 0.2307 - val_accuracy: 0.9376\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.2332 - accuracy: 0.9348 - val_loss: 0.2204 - val_accuracy: 0.9394\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.2226 - accuracy: 0.9376 - val_loss: 0.2131 - val_accuracy: 0.9420\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 1s 23us/sample - loss: 0.2123 - accuracy: 0.9406 - val_loss: 0.2047 - val_accuracy: 0.9440\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd390157f10>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 50\n",
    "\n",
    "model1.fit(X_train, y_train, epochs=n_epochs,\n",
    "          batch_size=n_batches,\n",
    "          shuffle=True,\n",
    "#          validation_split=0.1,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          validation_freq=1,\n",
    "          callbacks=[tensorboard_callback]          \n",
    "         )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 0s - loss: 0.2086 - accuracy: 0.9401\n",
      "\n",
      "Test Accuracy: 0.9401\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model1.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print('\\nTest Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the book uses `tensorflow.contrib.layers.batch_norm()` rather than `tf.layers.batch_normalization()` (which did not exist when this chapter was written). It is now preferable to use `tf.layers.batch_normalization()`, because anything in the contrib module may change or be deleted without notice. Instead of using the `batch_norm()` function as a regularizer parameter to the `fully_connected()` function, we now use `batch_normalization()` and we explicitly create a distinct layer. The parameters are a bit different, in particular:\n",
    "* `decay` is renamed to `momentum`,\n",
    "* `is_training` is renamed to `training`,\n",
    "* `updates_collections` is removed: the update operations needed by batch normalization are added to the `UPDATE_OPS` collection and you need to explicity run these operations during training (see the execution phase below),\n",
    "* we don't need to specify `scale=True`, as that is the default.\n",
    "\n",
    "Also note that in order to run batch norm just _before_ each hidden layer's activation function, we apply the ELU activation function manually, right after the batch norm layer.\n",
    "\n",
    "Note: since the `tf.layers.dense()` function is incompatible with `tf.contrib.layers.arg_scope()` (which is used in the book), we now use python's `functools.partial()` function instead. It makes it easy to create a `my_dense_layer()` function that just calls `tf.layers.dense()` with the desired parameters automatically set (unless they are overridden when calling `my_dense_layer()`). As you can see, the code remains very similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset_graph()\n",
    "\n",
    "#import tensorflow as tf\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "learning_rate = 0.01\n",
    "\n",
    "n_epochs = 5\n",
    "batch_size = 50\n",
    "\n",
    "model2 = keras.Sequential([\n",
    "    keras.layers.Dense(n_hidden1, kernel_initializer=he_init, activation=None),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.ELU(),\n",
    "    keras.layers.Dense(n_hidden2, kernel_initializer=he_init, activation=None),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.ELU(),\n",
    "    keras.layers.Dense(n_outputs, kernel_initializer=he_init, activation='softmax')\n",
    "])    \n",
    "\n",
    "model2.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "log_dir=\"logs_11/model2/\"\n",
    "\n",
    "file_writer = tf.summary.create_file_writer(log_dir + \"/metrics\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, \n",
    "                                                      update_freq=10, profile_batch = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 2s 36us/sample - loss: 0.5662 - accuracy: 0.8371 - val_loss: 0.3436 - val_accuracy: 0.9064\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 2s 30us/sample - loss: 0.3358 - accuracy: 0.9052 - val_loss: 0.2779 - val_accuracy: 0.9276\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 2s 31us/sample - loss: 0.2859 - accuracy: 0.9186 - val_loss: 0.2462 - val_accuracy: 0.9320\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 2s 30us/sample - loss: 0.2573 - accuracy: 0.9267 - val_loss: 0.2237 - val_accuracy: 0.9378\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 2s 30us/sample - loss: 0.2334 - accuracy: 0.9341 - val_loss: 0.2072 - val_accuracy: 0.9434\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd39007f310>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reset_graph()\n",
    "\n",
    "model2.fit(X_train, y_train, epochs=n_epochs,\n",
    "          batch_size=n_batches,\n",
    "          shuffle=True,\n",
    "#          validation_split=0.1,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          validation_freq=1,\n",
    "          callbacks=[tensorboard_callback]          \n",
    "         )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: logs_11/model2/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model2, log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 0s - loss: 0.2078 - accuracy: 0.9404\n",
      "\n",
      "Test Accuracy: 0.9404\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model2.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print('\\nTest Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid repeating the same parameters over and over again, we can use Python's `partial()` function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a neural net for MNIST, using the ELU activation function and Batch Normalization at each layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "BN_momentum = 0.9\n",
    "\n",
    "my_dense_layer = partial(keras.layers.Dense,\n",
    "            kernel_initializer=he_init)\n",
    "\n",
    "model3 = keras.Sequential([\n",
    "    my_dense_layer(n_hidden1, activation=None),\n",
    "    keras.layers.BatchNormalization(momentum=BN_momentum),\n",
    "    keras.layers.ELU(),\n",
    "    my_dense_layer(n_hidden2, activation=None),\n",
    "    keras.layers.BatchNormalization(momentum=BN_momentum),\n",
    "    keras.layers.ELU(),\n",
    "    my_dense_layer(n_outputs, activation='softmax')\n",
    "])    \n",
    "\n",
    "model3.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "log_dir=\"logs_11/model3/\"\n",
    "\n",
    "file_writer = tf.summary.create_file_writer(log_dir + \"/metrics\")\n",
    "#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, \n",
    "#                                                      update_freq=10, profile_batch = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving checkpoint at each epoch. Only weights are saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "54000/55000 [============================>.] - ETA: 0s - loss: 0.3235 - accuracy: 0.9040\n",
      "Epoch 00001: saving model to logs_11/model3/cp.ckpt\n",
      "55000/55000 [==============================] - 2s 33us/sample - loss: 0.3214 - accuracy: 0.9044 - val_loss: 0.1853 - val_accuracy: 0.9498\n",
      "Epoch 2/5\n",
      "54500/55000 [============================>.] - ETA: 0s - loss: 0.1689 - accuracy: 0.9515\n",
      "Epoch 00002: saving model to logs_11/model3/cp.ckpt\n",
      "55000/55000 [==============================] - 1s 26us/sample - loss: 0.1689 - accuracy: 0.9515 - val_loss: 0.1378 - val_accuracy: 0.9606\n",
      "Epoch 3/5\n",
      "53900/55000 [============================>.] - ETA: 0s - loss: 0.1240 - accuracy: 0.9642\n",
      "Epoch 00003: saving model to logs_11/model3/cp.ckpt\n",
      "55000/55000 [==============================] - 1s 27us/sample - loss: 0.1237 - accuracy: 0.9644 - val_loss: 0.1138 - val_accuracy: 0.9662\n",
      "Epoch 4/5\n",
      "54500/55000 [============================>.] - ETA: 0s - loss: 0.0965 - accuracy: 0.9717\n",
      "Epoch 00004: saving model to logs_11/model3/cp.ckpt\n",
      "55000/55000 [==============================] - 1s 26us/sample - loss: 0.0967 - accuracy: 0.9717 - val_loss: 0.1058 - val_accuracy: 0.9698\n",
      "Epoch 5/5\n",
      "54400/55000 [============================>.] - ETA: 0s - loss: 0.0788 - accuracy: 0.9765\n",
      "Epoch 00005: saving model to logs_11/model3/cp.ckpt\n",
      "55000/55000 [==============================] - 1s 26us/sample - loss: 0.0787 - accuracy: 0.9766 - val_loss: 0.0862 - val_accuracy: 0.9756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd3b4310cd0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = log_dir + \"cp.ckpt\"\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                                 save_weights_only=True, verbose=1)\n",
    "\n",
    "model3.fit(X_train, y_train, epochs=n_epochs,\n",
    "          batch_size=n_batches,\n",
    "          shuffle=True,\n",
    "#          validation_split=0.1,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          validation_freq=1,\n",
    "          callbacks=[cp_callback]          \n",
    "         )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: logs_11/model3/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model3, log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 0s - loss: 0.0863 - accuracy: 0.9735\n",
      "\n",
      "Test Accuracy: 0.9735\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model3.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print('\\nTest Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch Norm and ELU shine mostly for much deeper nets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Clipping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a simple neural net for MNIST and add gradient clipping. The first part is the same as earlier (except we added a few more layers to demonstrate reusing pretrained models, see below):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we apply gradient clipping. For this, we need to get the gradients, use the `clipvalue` argument to clip them, then apply them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_hidden3 = 50\n",
    "n_outputs = 10\n",
    "learning_rate = 0.01\n",
    "threshold = 1.0\n",
    "\n",
    "def create_model():\n",
    "  model = keras.Sequential([\n",
    "    keras.layers.Dense(n_hidden1, kernel_initializer=he_init, activation='relu'),\n",
    "    keras.layers.Dense(n_hidden2, kernel_initializer=he_init, activation='relu'),\n",
    "    keras.layers.Dense(n_hidden3, kernel_initializer=he_init, activation='relu'),\n",
    "    keras.layers.Dense(n_outputs, kernel_initializer=he_init, activation='softmax')\n",
    "])    \n",
    "  model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9, clipvalue=threshold),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "  return model\n",
    "\n",
    "model4 = create_model()\n",
    "\n",
    "# clipvalue: -threshold ~ threshold\n",
    "\n",
    "log_dir=\"logs_11/model4/\"\n",
    "\n",
    "file_writer = tf.summary.create_file_writer(log_dir + \"/metrics\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, \n",
    "                                                      update_freq=10, profile_batch = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 3s 49us/sample - loss: 0.3027 - accuracy: 0.9080 - val_loss: 0.1304 - val_accuracy: 0.9618\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 3s 46us/sample - loss: 0.1152 - accuracy: 0.9645 - val_loss: 0.0979 - val_accuracy: 0.9716\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 3s 46us/sample - loss: 0.0767 - accuracy: 0.9763 - val_loss: 0.0823 - val_accuracy: 0.9752\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 2s 45us/sample - loss: 0.0579 - accuracy: 0.9816 - val_loss: 0.0949 - val_accuracy: 0.9720\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 2s 45us/sample - loss: 0.0435 - accuracy: 0.9866 - val_loss: 0.0793 - val_accuracy: 0.9762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd37c20b050>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "n_batches = 50\n",
    "\n",
    "model4.fit(X_train, y_train, epochs=n_epochs,\n",
    "          batch_size=n_batches,\n",
    "          shuffle=True,\n",
    "#          validation_split=0.1,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          validation_freq=1,\n",
    "          callbacks=[tensorboard_callback]          \n",
    "         )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest is the same as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: logs_11/model4/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model4, log_dir)\n",
    "model4.save(log_dir + \"model4.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 0s - loss: 0.0842 - accuracy: 0.9741\n",
      "\n",
      "Test Accuracy: 0.9741\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model4.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print('\\nTest Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reusing Pretrained Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reusing a TensorFlow Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First you need to load the graph's structure. The `import_meta_graph()` function does just that, loading the graph's operations into the default graph, and returning a `Saver` that you can then use to restore the model's state. Note that by default, a `Saver` saves the structure of the graph into a `.meta` file, so that's the file you should load:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loaded model below is not a Kera model\n",
    "# model_imported = tf.saved_model.load(log_dir)\n",
    "\n",
    "# Loading Keras model\n",
    "model_imported = keras.models.load_model(log_dir)\n",
    "#model_imported = keras.models.load_model(log_dir + \"/model4/model4.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next you need to get a handle on all the operations you will need for training. If you don't know the graph's structure, you can list all the operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 0s - loss: 0.0842 - accuracy: 0.9741\n",
      "\n",
      "Test Accuracy: 0.9741\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_imported.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print('\\nTest Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             multiple                  235500    \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             multiple                  15050     \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             multiple                  2550      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             multiple                  510       \n",
      "=================================================================\n",
      "Total params: 253,610\n",
      "Trainable params: 253,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_imported.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1e48a2b5e1d08da8\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1e48a2b5e1d08da8\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir ./logs_11/model4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue to train for another 5 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 3s 50us/sample - loss: 0.0223 - accuracy: 0.9936 - val_loss: 0.0599 - val_accuracy: 0.9840\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 3s 46us/sample - loss: 0.0176 - accuracy: 0.9957 - val_loss: 0.0592 - val_accuracy: 0.9838\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 3s 46us/sample - loss: 0.0159 - accuracy: 0.9964 - val_loss: 0.0587 - val_accuracy: 0.9842\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 3s 45us/sample - loss: 0.0149 - accuracy: 0.9967 - val_loss: 0.0587 - val_accuracy: 0.9836\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 3s 46us/sample - loss: 0.0141 - accuracy: 0.9971 - val_loss: 0.0584 - val_accuracy: 0.9840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd37c44fed0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 50\n",
    "learning_rate = 0.005\n",
    "model_imported.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model_imported.fit(X_train, y_train, epochs=n_epochs,\n",
    "          batch_size=n_batches,\n",
    "          shuffle=True,\n",
    "#          validation_split=0.1,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          validation_freq=1,\n",
    "          callbacks=[tensorboard_callback]          \n",
    "         )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 0s - loss: 0.0633 - accuracy: 0.9799\n",
      "\n",
      "Test Accuracy: 0.9799\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_imported.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print('\\nTest Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Practice]\n",
    "**Train above model for n_epoch=10 from the scratch and compare the results**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reusing a TensorFlow Model - freezing lower layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             multiple                  235500    \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             multiple                  15050     \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             multiple                  2550      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             multiple                  510       \n",
      "=================================================================\n",
      "Total params: 253,610\n",
      "Trainable params: 253,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[[ 0.00090821 -0.09130193  0.00594834 ...  0.07482573  0.08217672\n",
      "  -0.06880955]\n",
      " [-0.00243217  0.02089237  0.02092533 ... -0.00499101  0.00867761\n",
      "   0.00245165]\n",
      " [-0.0469807  -0.00284685 -0.00951752 ... -0.03931122  0.04587793\n",
      "  -0.11098105]\n",
      " ...\n",
      " [-0.04045086  0.02069145 -0.02827263 ... -0.08117317 -0.00991384\n",
      "   0.06026252]\n",
      " [ 0.03114422 -0.0059074   0.04558625 ... -0.00533671  0.04747976\n",
      "   0.00833549]\n",
      " [-0.07708663 -0.06651046  0.0249394  ... -0.05330391 -0.01876666\n",
      "  -0.02390632]]\n",
      "10000/10000 - 0s - loss: 0.0842 - accuracy: 0.9741\n"
     ]
    }
   ],
   "source": [
    "model_imported1 = keras.models.load_model(log_dir+'model4.h5')\n",
    "model_imported1.summary()\n",
    "weights_before=model_imported.layers[0].get_weights()\n",
    "print(weights_before[0])\n",
    "test_loss, test_acc = model_imported1.evaluate(X_test,  y_test, verbose=2)\n",
    "#tf.print(model_imported1.layers[-4])\n",
    "#tf.print(model_imported1.layers[-3])\n",
    "#tf.print(model_imported1.layers[-2])\n",
    "#tf.print(model_imported1.layers[-1])\n",
    "#tf.print(model_imported1.layers[0])\n",
    "#tf.print(model_imported1.layers[1])\n",
    "#tf.print(model_imported1.layers[2])\n",
    "#tf.print(model_imported1.layers[3])\n",
    "#tf.print(model_imported1.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 3s 48us/sample - loss: 0.0723 - accuracy: 0.9789 - val_loss: 0.0811 - val_accuracy: 0.9784\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 3s 46us/sample - loss: 0.0304 - accuracy: 0.9906 - val_loss: 0.0814 - val_accuracy: 0.9808\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 2s 45us/sample - loss: 0.0285 - accuracy: 0.9913 - val_loss: 0.0760 - val_accuracy: 0.9800\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 2s 45us/sample - loss: 0.0256 - accuracy: 0.9921 - val_loss: 0.0805 - val_accuracy: 0.9802\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 2s 44us/sample - loss: 0.0233 - accuracy: 0.9927 - val_loss: 0.0783 - val_accuracy: 0.9810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd440e0fa10>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_hidden4 = 50\n",
    "n_hidden5 = 50\n",
    "n_outputs = 10\n",
    "learning_rate = 0.01\n",
    "threshold = 1.0\n",
    "n_epochs = 5\n",
    "n_batches = 50\n",
    "model_imported1.trainable = False\n",
    "\n",
    "#x = model_imported1.layers[-2].output\n",
    "#x = keras.layers.Dense(n_hidden4, kernel_initializer=he_init, activation='relu')(x)\n",
    "#x = keras.layers.Dense(n_hidden5, kernel_initializer=he_init, activation='relu')(x)\n",
    "#x = keras.layers.Dense(n_outputs, kernel_initializer=he_init, activation='softmax')(x)\n",
    "\n",
    "#new_model = keras.models.Model(model_imported1.input, x, name = 'new_model')\n",
    "new_model = keras.Sequential([\n",
    "    model_imported1.layers[-4],\n",
    "    model_imported1.layers[-3],\n",
    "    model_imported1.layers[-2],\n",
    "    keras.layers.Dense(n_hidden4, kernel_initializer=he_init, activation='relu'),\n",
    "    keras.layers.Dense(n_hidden5, kernel_initializer=he_init, activation='relu'),\n",
    "    keras.layers.Dense(n_outputs, kernel_initializer=he_init, activation='softmax')\n",
    "])\n",
    "new_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9, clipvalue=threshold),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "new_model.fit(X_train, y_train, epochs=n_epochs,\n",
    "          batch_size=n_batches,\n",
    "          shuffle=True,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          validation_freq=1,\n",
    "          callbacks=[tensorboard_callback]          \n",
    "         )  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             multiple                  235500    \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             multiple                  15050     \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             multiple                  2550      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             multiple                  2550      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             multiple                  2550      \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             multiple                  510       \n",
      "=================================================================\n",
      "Total params: 258,710\n",
      "Trainable params: 5,610\n",
      "Non-trainable params: 253,100\n",
      "_________________________________________________________________\n",
      "[[ 0.00090821 -0.09130193  0.00594834 ...  0.07482573  0.08217672\n",
      "  -0.06880955]\n",
      " [-0.00243217  0.02089237  0.02092533 ... -0.00499101  0.00867761\n",
      "   0.00245165]\n",
      " [-0.0469807  -0.00284685 -0.00951752 ... -0.03931122  0.04587793\n",
      "  -0.11098105]\n",
      " ...\n",
      " [-0.04045086  0.02069145 -0.02827263 ... -0.08117317 -0.00991384\n",
      "   0.06026252]\n",
      " [ 0.03114422 -0.0059074   0.04558625 ... -0.00533671  0.04747976\n",
      "   0.00833549]\n",
      " [-0.07708663 -0.06651046  0.0249394  ... -0.05330391 -0.01876666\n",
      "  -0.02390632]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(784, 300), dtype=bool, numpy=\n",
       "array([[ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       ...,\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True]])>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.summary()\n",
    "weights_after=new_model.layers[0].get_weights()\n",
    "print(weights_after[0])\n",
    "tf.math.equal(weights_before[0], weights_after[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faster Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 3s 49us/sample - loss: 0.0653 - accuracy: 0.9786 - val_loss: 0.0989 - val_accuracy: 0.9684\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 2s 45us/sample - loss: 0.0485 - accuracy: 0.9841 - val_loss: 0.0951 - val_accuracy: 0.9728\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 2s 45us/sample - loss: 0.0358 - accuracy: 0.9885 - val_loss: 0.0801 - val_accuracy: 0.9804\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 2s 44us/sample - loss: 0.0263 - accuracy: 0.9917 - val_loss: 0.0729 - val_accuracy: 0.9824\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 2s 45us/sample - loss: 0.0191 - accuracy: 0.9945 - val_loss: 0.0823 - val_accuracy: 0.9782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd3a6653810>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=n_epochs,\n",
    "          batch_size=n_batches,\n",
    "          shuffle=True,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          validation_freq=1,\n",
    "          callbacks=[tensorboard_callback]          \n",
    "         )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nesterov Accelerated Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=n_epochs,\n",
    "          batch_size=n_batches,\n",
    "          shuffle=True,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          validation_freq=1,\n",
    "          callbacks=[tensorboard_callback]          \n",
    "         )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model5.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=learning_rate),\n",
    "#              loss='sparse_categorical_crossentropy',\n",
    "#              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model5.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=learning_rate, momentum=0.9),\n",
    "#              loss='sparse_categorical_crossentropy',\n",
    "#              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model5.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "#              loss='sparse_categorical_crossentropy',\n",
    "#              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Practice]\n",
    "**Apply faster optimizers with various parameters and compare the results of execution times and accuracies**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "he_init = tf.keras.initializers.he_normal(seed=42)\n",
    "\n",
    "model6 = keras.Sequential([\n",
    "    keras.layers.Dense(n_hidden1, kernel_initializer=he_init, activation=leaky_relu),\n",
    "    keras.layers.Dense(n_hidden2, kernel_initializer=he_init, activation=leaky_relu),\n",
    "    keras.layers.Dense(n_outputs, kernel_initializer=he_init, activation='softmax')\n",
    "])    \n",
    "\n",
    "initial_learning_rate=0.1\n",
    "decay_steps = 10000\n",
    "decay_rate = 1/10\n",
    "# global_step = tf.Variable(0, trainable=False, name=\"global_step\")\n",
    "learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate, decay_steps, decay_rate)\n",
    "\n",
    "model6.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir=\"logs_11/model6/\"\n",
    "file_writer = tf.summary.create_file_writer(log_dir + \"/metrics\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, \n",
    "                                                      update_freq=10, profile_batch = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 3s 50us/sample - loss: 0.2424 - accuracy: 0.9277 - val_loss: 0.1291 - val_accuracy: 0.9604\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 3s 46us/sample - loss: 0.1038 - accuracy: 0.9687 - val_loss: 0.1011 - val_accuracy: 0.9704\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 3s 46us/sample - loss: 0.0628 - accuracy: 0.9806 - val_loss: 0.0776 - val_accuracy: 0.9784\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 2s 45us/sample - loss: 0.0346 - accuracy: 0.9892 - val_loss: 0.0826 - val_accuracy: 0.9780\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 3s 46us/sample - loss: 0.0207 - accuracy: 0.9932 - val_loss: 0.0697 - val_accuracy: 0.9814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd440bdbf50>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "n_batches = 50\n",
    "\n",
    "model6.fit(X_train, y_train, epochs=n_epochs,\n",
    "          batch_size=n_batches,\n",
    "          shuffle=True,\n",
    "#          validation_split=0.1,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          validation_freq=1,\n",
    "          callbacks=[tensorboard_callback]          \n",
    "         )    \n",
    "#tf.print(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 0s - loss: 0.0659 - accuracy: 0.9811\n",
      "\n",
      "Test Accuracy: 0.9811\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model6.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print('\\nTest Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avoiding Overfitting Through Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\ell_1$ and $\\ell_2$ regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's implement $\\ell_1$ regularization manually. First, we create the model, as usual (with just one hidden layer this time, for simplicity):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "he_init = tf.keras.initializers.he_normal(seed=42)\n",
    "l1=tf.keras.regularizers.l1(l=0.01)\n",
    "#l2=tf.keras.regularizers.l1(l=0.01)\n",
    "\n",
    "model7 = keras.Sequential([\n",
    "    keras.layers.Dense(n_hidden1, kernel_initializer=he_init, kernel_regularizer=l1, activation=leaky_relu),\n",
    "    keras.layers.Dense(n_hidden2, kernel_initializer=he_init, kernel_regularizer=l1, activation=leaky_relu),\n",
    "    keras.layers.Dense(n_outputs, kernel_initializer=he_init, kernel_regularizer=l1, activation='softmax')\n",
    "])    \n",
    "\n",
    "initial_learning_rate=0.1\n",
    "decay_steps = 10000\n",
    "decay_rate = 1/10\n",
    "# global_step = tf.Variable(0, trainable=False, name=\"global_step\")\n",
    "learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate, decay_steps, decay_rate)\n",
    "\n",
    "model7.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we get a handle on the layer weights, and we compute the total loss, which is equal to the sum of the usual cross entropy loss and the $\\ell_1$ loss (i.e., the absolute values of the weights):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir=\"logs_11/model7/\"\n",
    "file_writer = tf.summary.create_file_writer(log_dir + \"/metrics\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, \n",
    "                                                      update_freq=10, profile_batch = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 3s 53us/sample - loss: 5.7950 - accuracy: 0.6839 - val_loss: 3.8877 - val_accuracy: 0.7768\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 3s 49us/sample - loss: 3.7224 - accuracy: 0.7391 - val_loss: 3.2242 - val_accuracy: 0.8078\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 3s 48us/sample - loss: 3.1275 - accuracy: 0.7613 - val_loss: 2.7668 - val_accuracy: 0.8206\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 3s 48us/sample - loss: 2.6846 - accuracy: 0.7836 - val_loss: 2.3516 - val_accuracy: 0.8500\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 3s 48us/sample - loss: 2.3696 - accuracy: 0.7956 - val_loss: 2.1132 - val_accuracy: 0.8484\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd4409bed10>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "n_batches = 50\n",
    "\n",
    "model7.fit(X_train, y_train, epochs=n_epochs,\n",
    "          batch_size=n_batches,\n",
    "          shuffle=True,\n",
    "#          validation_split=0.1,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          validation_freq=1,\n",
    "          callbacks=[tensorboard_callback]          \n",
    "         )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 0s - loss: 2.1155 - accuracy: 0.8459\n",
      "\n",
      "Test Accuracy: 0.8459\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model7.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print('\\nTest Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Practice]\n",
    "**Training the above network using various scales (l values)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the book uses `tf.contrib.layers.dropout()` rather than `tf.layers.dropout()` (which did not exist when this chapter was written). It is now preferable to use `tf.layers.dropout()`, because anything in the contrib module may change or be deleted without notice. The `tf.layers.dropout()` function is almost identical to the `tf.contrib.layers.dropout()` function, except for a few minor differences. Most importantly:\n",
    "* you must specify the dropout rate (`rate`) rather than the keep probability (`keep_prob`), where `rate` is simply equal to `1 - keep_prob`,\n",
    "* the `is_training` parameter is renamed to `training`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "learning_rate = 0.01\n",
    "dropout_rate = 0.5  # == 1 - keep_prob\n",
    "\n",
    "n_epochs = 5\n",
    "batch_size = 50\n",
    "\n",
    "model8 = keras.Sequential([\n",
    "    keras.layers.Dropout(rate=dropout_rate),\n",
    "    keras.layers.Dense(n_hidden1, kernel_initializer=he_init, activation='relu'),\n",
    "    keras.layers.Dropout(rate=dropout_rate),\n",
    "    keras.layers.Dense(n_hidden2, kernel_initializer=he_init, activation='relu'),\n",
    "    keras.layers.Dropout(rate=dropout_rate),\n",
    "    keras.layers.Dense(n_outputs, kernel_initializer=he_init, activation='softmax')\n",
    "])    \n",
    "\n",
    "model8.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "log_dir=\"logs_11/model8/\"\n",
    "\n",
    "file_writer = tf.summary.create_file_writer(log_dir + \"/metrics\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, \n",
    "                                                      update_freq=10, profile_batch = 0)\n",
    "checkpoint_path = log_dir + \"cp.ckpt\"\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                                 save_weights_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "53750/55000 [============================>.] - ETA: 0s - loss: 1.6213 - accuracy: 0.4394\n",
      "Epoch 00001: saving model to logs_11/model8/cp.ckpt\n",
      "55000/55000 [==============================] - 2s 37us/sample - loss: 1.6114 - accuracy: 0.4426 - val_loss: 0.6934 - val_accuracy: 0.8310\n",
      "Epoch 2/5\n",
      "54800/55000 [============================>.] - ETA: 0s - loss: 0.9965 - accuracy: 0.6646\n",
      "Epoch 00002: saving model to logs_11/model8/cp.ckpt\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 0.9957 - accuracy: 0.6648 - val_loss: 0.4983 - val_accuracy: 0.8758\n",
      "Epoch 3/5\n",
      "53650/55000 [============================>.] - ETA: 0s - loss: 0.8405 - accuracy: 0.7232\n",
      "Epoch 00003: saving model to logs_11/model8/cp.ckpt\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 0.8386 - accuracy: 0.7238 - val_loss: 0.4201 - val_accuracy: 0.8956\n",
      "Epoch 4/5\n",
      "53950/55000 [============================>.] - ETA: 0s - loss: 0.7462 - accuracy: 0.7599\n",
      "Epoch 00004: saving model to logs_11/model8/cp.ckpt\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 0.7462 - accuracy: 0.7600 - val_loss: 0.3707 - val_accuracy: 0.9058\n",
      "Epoch 5/5\n",
      "54300/55000 [============================>.] - ETA: 0s - loss: 0.6843 - accuracy: 0.7826\n",
      "Epoch 00005: saving model to logs_11/model8/cp.ckpt\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 0.6842 - accuracy: 0.7826 - val_loss: 0.3382 - val_accuracy: 0.9136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd440894ed0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 50\n",
    "\n",
    "model8.fit(X_train, y_train, epochs=n_epochs,\n",
    "          batch_size=n_batches,\n",
    "          shuffle=True,\n",
    "#          validation_split=0.1,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          validation_freq=1,\n",
    "          callbacks=[cp_callback]          \n",
    "         )  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 1s - loss: 0.3351 - accuracy: 0.9117\n",
      "\n",
      "Test Accuracy: 0.9117\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model8.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print('\\nTest Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: logs_11/model8/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model8, log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go back to a plain and simple neural net for MNIST with just 2 hidden layers:\n",
    "MaxNorm: L2 norm of weights are less than 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "#MaxNorm=tf.keras.constraints.MaxNorm(max_value=1, axis=1)\n",
    "MaxNorm=tf.keras.constraints.MaxNorm(max_value=1, axis=0)\n",
    "\n",
    "model9 = keras.Sequential([\n",
    "    keras.layers.Dense(n_hidden1, kernel_initializer=he_init, kernel_constraint=MaxNorm, activation='relu'),\n",
    "    keras.layers.Dense(n_hidden2, kernel_initializer=he_init, kernel_constraint=MaxNorm, activation='relu'),\n",
    "    keras.layers.Dense(n_outputs, kernel_initializer=he_init, kernel_constraint=MaxNorm, activation='softmax')\n",
    "])    \n",
    "\n",
    "model9.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=momentum),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "log_dir=\"logs_11/model9/\"\n",
    "\n",
    "file_writer = tf.summary.create_file_writer(log_dir + \"/metrics\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, \n",
    "                                                      update_freq=10, profile_batch = 0)\n",
    "checkpoint_path = log_dir + \"cp.ckpt\"\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                                 save_weights_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "54200/55000 [============================>.] - ETA: 0s - loss: 0.4396 - accuracy: 0.8783\n",
      "Epoch 00001: saving model to logs_11/model9/cp.ckpt\n",
      "55000/55000 [==============================] - 2s 42us/sample - loss: 0.4368 - accuracy: 0.8790 - val_loss: 0.2308 - val_accuracy: 0.9326\n",
      "Epoch 2/5\n",
      "53550/55000 [============================>.] - ETA: 0s - loss: 0.2210 - accuracy: 0.9377\n",
      "Epoch 00002: saving model to logs_11/model9/cp.ckpt\n",
      "55000/55000 [==============================] - 2s 38us/sample - loss: 0.2207 - accuracy: 0.9377 - val_loss: 0.1846 - val_accuracy: 0.9476\n",
      "Epoch 3/5\n",
      "54400/55000 [============================>.] - ETA: 0s - loss: 0.1729 - accuracy: 0.9514\n",
      "Epoch 00003: saving model to logs_11/model9/cp.ckpt\n",
      "55000/55000 [==============================] - 2s 38us/sample - loss: 0.1730 - accuracy: 0.9514 - val_loss: 0.1481 - val_accuracy: 0.9612\n",
      "Epoch 4/5\n",
      "53850/55000 [============================>.] - ETA: 0s - loss: 0.1465 - accuracy: 0.9588\n",
      "Epoch 00004: saving model to logs_11/model9/cp.ckpt\n",
      "55000/55000 [==============================] - 2s 38us/sample - loss: 0.1462 - accuracy: 0.9590 - val_loss: 0.1308 - val_accuracy: 0.9660\n",
      "Epoch 5/5\n",
      "54050/55000 [============================>.] - ETA: 0s - loss: 0.1273 - accuracy: 0.9650\n",
      "Epoch 00005: saving model to logs_11/model9/cp.ckpt\n",
      "55000/55000 [==============================] - 2s 38us/sample - loss: 0.1273 - accuracy: 0.9649 - val_loss: 0.1324 - val_accuracy: 0.9656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd37c60cdd0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "n_batches = 50\n",
    "\n",
    "model9.fit(X_train, y_train, epochs=n_epochs,\n",
    "          batch_size=n_batches,\n",
    "          shuffle=True,\n",
    "#          validation_split=0.1,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          validation_freq=1,\n",
    "          callbacks=[cp_callback]          \n",
    "         )  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 0s - loss: 0.1372 - accuracy: 0.9605\n",
      "\n",
      "Test Accuracy: 0.9605\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model9.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print('\\nTest Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 28, 28, 1)\n",
      "(55000,)\n",
      "(5000, 28, 28, 1)\n",
      "(5000,)\n",
      "(10000, 28, 28, 1)\n",
      "(10000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data augmentation example: shift, rotate, resize, flip, shear, blur, crop, change contrasts/brightness/saturation/hue\n",
    "import random\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import datetime\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization=True,\n",
    "        rotation_range=20,    # max rotation angle. 0: no rotation\n",
    "        width_shift_range=0.3,# max horizontal shift. 0: no shift\n",
    "        height_shift_range=0.3,# max vertical shift. 0: no shift\n",
    "        shear_range=0.5,       # max shear range. 0: no shear\n",
    "        zoom_range=(0.9, 2.0), # Scaling range: 0.9 ~ 2. a number: [1-number, 1+number]. 0: no scaling\n",
    "        horizontal_flip=False, # no horizontal flip.\n",
    "        vertical_flip=False,   # no vertical flip\n",
    "        fill_mode='constant',\n",
    "        cval=0,\n",
    ")\n",
    "\n",
    "X_train = X_train_2d.astype(np.float32).reshape((-1, 28, 28,1))\n",
    "#X_train = X_train.astype('float32')\n",
    "y_train = y_train_0.astype(np.int32)\n",
    "#y_train = y_train_0.astype('int32')\n",
    "X_test = X_test_2d.astype(np.float32).reshape((X_test_2d.shape[0], 28, 28,1))\n",
    "y_test = y_test_0.astype(np.int32)\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# configure batch size and retrieve one batch of images\n",
    "for x_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9):\n",
    "    # create a grid of 3x3 images\n",
    "    for i in range(0, 9):\n",
    "        plt.subplot(330 + 1 + i)\n",
    "        plt.imshow(x_batch[i].reshape(28, 28), cmap=plt.get_cmap('gray'))\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "    break\n",
    "\n",
    "#\n",
    "#train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "#test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "\n",
    "#train_dataset = train_dataset.shuffle(NUM_TRAIN_SAMPLES).batch(n_batches, drop_remainder=True)\n",
    "#test_dataset = test_dataset.batch(n_batches, drop_remainder=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1100 steps, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "1100/1100 [==============================] - 15s 14ms/step - loss: 1.5192 - accuracy: 0.4849 - val_loss: 248.9612 - val_accuracy: 0.3200\n",
      "Epoch 2/5\n",
      "1100/1100 [==============================] - 15s 13ms/step - loss: 0.9765 - accuracy: 0.6790 - val_loss: 366.9779 - val_accuracy: 0.2980\n",
      "Epoch 3/5\n",
      "1100/1100 [==============================] - 15s 13ms/step - loss: 0.8161 - accuracy: 0.7356 - val_loss: 353.5507 - val_accuracy: 0.3368\n",
      "Epoch 4/5\n",
      "1100/1100 [==============================] - 15s 13ms/step - loss: 0.7221 - accuracy: 0.7671 - val_loss: 346.7899 - val_accuracy: 0.3376\n",
      "Epoch 5/5\n",
      "1100/1100 [==============================] - 15s 13ms/step - loss: 0.6652 - accuracy: 0.7890 - val_loss: 368.3615 - val_accuracy: 0.3294\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd3af506e10>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_inputs = 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "n_epochs = 5\n",
    "n_batches = 50\n",
    "\n",
    "model10 = tf.keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(n_inputs, n_inputs,1)),\n",
    "    keras.layers.Dense(n_hidden1,  kernel_initializer=he_init),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.Dense(n_hidden2,  kernel_initializer=he_init),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.Dense(n_outputs,  kernel_initializer=he_init, activation='softmax'),\n",
    "])\n",
    "\n",
    "#modelcompile\n",
    "model10.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=momentum),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "log_dir=\"logs_11/model10/\"\n",
    "\n",
    "file_writer = tf.summary.create_file_writer(log_dir + \"/metrics\")\n",
    "#file_writer.set_as_default()\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch = 0)\n",
    "\n",
    "n_epochs = 5\n",
    "n_batches = 50\n",
    "model10.fit(datagen.flow(X_train, y_train, batch_size=n_batches, shuffle=True), \n",
    "          epochs=n_epochs,\n",
    "          validation_data=(X_valid, y_valid), \n",
    "          validation_freq=1,\n",
    "          callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 1s - loss: 368.6114 - accuracy: 0.3347\n",
      "\n",
      "Test Accuracy: 0.3347\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model10.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print('\\nTest Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "nav_menu": {
   "height": "360px",
   "width": "416px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
